{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9880879c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082697e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e149882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available with 1 GPU(s).\n",
      "\n",
      "GPU 0: NVIDIA GeForce GTX 1650\n",
      "  Compute Capability: 7.5\n",
      "  Total Memory: 4.00 GB\n",
      "\n",
      "Current default device for tensors: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available with {torch.cuda.device_count()} GPU(s).\")\n",
    "\n",
    "    # Iterate through available GPUs and print their details\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"\\nGPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "        print(f\"  Total Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# To get the current device PyTorch is configured to use (e.g., for tensors)\n",
    "current_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nCurrent default device for tensors: {current_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a13da8",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4c1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"data\", \"books\",\"raw\")\n",
    "users_dir = os.path.join(data_dir, \"Users.csv\")\n",
    "ratings_dir = os.path.join(data_dir, \"Ratings.csv\")\n",
    "books_dir = os.path.join(data_dir, \"Books.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c29b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(users_dir)\n",
    "df_ratings = pd.read_csv(ratings_dir)\n",
    "df_books = pd.read_csv(books_dir, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb1f4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a66c759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User-ID          0\n",
       "Location         0\n",
       "Age         110762\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fdb1613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278858 entries, 0 to 278857\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   User-ID   278858 non-null  int64  \n",
      " 1   Location  278858 non-null  object \n",
      " 2   Age       168096 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6fb05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>278858.00000</td>\n",
       "      <td>168096.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>139429.50000</td>\n",
       "      <td>34.751434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>80499.51502</td>\n",
       "      <td>14.428097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>69715.25000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>139429.50000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>209143.75000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>278858.00000</td>\n",
       "      <td>244.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User-ID            Age\n",
       "count  278858.00000  168096.000000\n",
       "mean   139429.50000      34.751434\n",
       "std     80499.51502      14.428097\n",
       "min         1.00000       0.000000\n",
       "25%     69715.25000      24.000000\n",
       "50%    139429.50000      32.000000\n",
       "75%    209143.75000      44.000000\n",
       "max    278858.00000     244.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab768193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278858"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users[\"User-ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25653d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278858, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914dacc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df44c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271360 entries, 0 to 271359\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   ISBN                 271360 non-null  object\n",
      " 1   Book-Title           271360 non-null  object\n",
      " 2   Book-Author          271358 non-null  object\n",
      " 3   Year-Of-Publication  271360 non-null  object\n",
      " 4   Publisher            271358 non-null  object\n",
      " 5   Image-URL-S          271360 non-null  object\n",
      " 6   Image-URL-M          271360 non-null  object\n",
      " 7   Image-URL-L          271357 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9e0fe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>271360</td>\n",
       "      <td>271360</td>\n",
       "      <td>271358</td>\n",
       "      <td>271360</td>\n",
       "      <td>271358</td>\n",
       "      <td>271360</td>\n",
       "      <td>271360</td>\n",
       "      <td>271357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>271360</td>\n",
       "      <td>242135</td>\n",
       "      <td>102022</td>\n",
       "      <td>118</td>\n",
       "      <td>16807</td>\n",
       "      <td>271044</td>\n",
       "      <td>271044</td>\n",
       "      <td>271041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Selected Poems</td>\n",
       "      <td>Agatha Christie</td>\n",
       "      <td>2002</td>\n",
       "      <td>Harlequin</td>\n",
       "      <td>http://images.amazon.com/images/P/185326119X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/185326119X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/225307649X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>632</td>\n",
       "      <td>17627</td>\n",
       "      <td>7535</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN      Book-Title      Book-Author Year-Of-Publication  \\\n",
       "count       271360          271360           271358              271360   \n",
       "unique      271360          242135           102022                 118   \n",
       "top     0195153448  Selected Poems  Agatha Christie                2002   \n",
       "freq             1              27              632               17627   \n",
       "\n",
       "        Publisher                                        Image-URL-S  \\\n",
       "count      271358                                             271360   \n",
       "unique      16807                                             271044   \n",
       "top     Harlequin  http://images.amazon.com/images/P/185326119X.0...   \n",
       "freq         7535                                                  2   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "count                                              271360   \n",
       "unique                                             271044   \n",
       "top     http://images.amazon.com/images/P/185326119X.0...   \n",
       "freq                                                    2   \n",
       "\n",
       "                                              Image-URL-L  \n",
       "count                                              271357  \n",
       "unique                                             271041  \n",
       "top     http://images.amazon.com/images/P/225307649X.0...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "450ae8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN                   0\n",
       "Book-Title             0\n",
       "Book-Author            2\n",
       "Year-Of-Publication    0\n",
       "Publisher              2\n",
       "Image-URL-S            0\n",
       "Image-URL-M            0\n",
       "Image-URL-L            3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4023e69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271360"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books[\"ISBN\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8986c716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mark P. O. Morford', 'Richard Bruce Wright', \"Carlo D'Este\", ...,\n",
       "       'David Biggs', 'Teri Sloat', 'Christopher  Biffle'],\n",
       "      shape=(102023,), dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books[\"Book-Author\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47ad9e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Oxford University Press', 'HarperFlamingo Canada',\n",
       "       'HarperPerennial', ..., 'Tempo', 'Life Works Books', 'Connaught'],\n",
       "      shape=(16808,), dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books[\"Publisher\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54cc2142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0195086295</td>\n",
       "      <td>What a Wonderful World: A Lifetime of Recordings</td>\n",
       "      <td>Bob Thiele</td>\n",
       "      <td>1995</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195086295.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195086295.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195086295.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0198320264</td>\n",
       "      <td>Julius Caesar (Oxford School Shakespeare)</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>2001</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0198320264.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0198320264.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0198320264.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0192815318</td>\n",
       "      <td>Cranford (The World's Classics)</td>\n",
       "      <td>Elizabeth Gaskell</td>\n",
       "      <td>1982</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192815318.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192815318.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192815318.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0198604025</td>\n",
       "      <td>How Not to Say What You Mean: A Dictionary of ...</td>\n",
       "      <td>R. W. Holder</td>\n",
       "      <td>2003</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0198604025.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0198604025.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0198604025.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ISBN                                         Book-Title  \\\n",
       "0    0195153448                                Classical Mythology   \n",
       "357  0195086295   What a Wonderful World: A Lifetime of Recordings   \n",
       "397  0198320264          Julius Caesar (Oxford School Shakespeare)   \n",
       "521  0192815318                    Cranford (The World's Classics)   \n",
       "817  0198604025  How Not to Say What You Mean: A Dictionary of ...   \n",
       "\n",
       "             Book-Author Year-Of-Publication                Publisher  \\\n",
       "0     Mark P. O. Morford                2002  Oxford University Press   \n",
       "357           Bob Thiele                1995  Oxford University Press   \n",
       "397  William Shakespeare                2001  Oxford University Press   \n",
       "521    Elizabeth Gaskell                1982  Oxford University Press   \n",
       "817         R. W. Holder                2003  Oxford University Press   \n",
       "\n",
       "                                           Image-URL-S  \\\n",
       "0    http://images.amazon.com/images/P/0195153448.0...   \n",
       "357  http://images.amazon.com/images/P/0195086295.0...   \n",
       "397  http://images.amazon.com/images/P/0198320264.0...   \n",
       "521  http://images.amazon.com/images/P/0192815318.0...   \n",
       "817  http://images.amazon.com/images/P/0198604025.0...   \n",
       "\n",
       "                                           Image-URL-M  \\\n",
       "0    http://images.amazon.com/images/P/0195153448.0...   \n",
       "357  http://images.amazon.com/images/P/0195086295.0...   \n",
       "397  http://images.amazon.com/images/P/0198320264.0...   \n",
       "521  http://images.amazon.com/images/P/0192815318.0...   \n",
       "817  http://images.amazon.com/images/P/0198604025.0...   \n",
       "\n",
       "                                           Image-URL-L  \n",
       "0    http://images.amazon.com/images/P/0195153448.0...  \n",
       "357  http://images.amazon.com/images/P/0195086295.0...  \n",
       "397  http://images.amazon.com/images/P/0198320264.0...  \n",
       "521  http://images.amazon.com/images/P/0192815318.0...  \n",
       "817  http://images.amazon.com/images/P/0198604025.0...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books[df_books[\"Publisher\"] == \"Oxford University Press\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26dd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271360, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06540c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149780 non-null  int64 \n",
      " 1   ISBN         1149780 non-null  object\n",
      " 2   Book-Rating  1149780 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 26.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.149780e+06</td>\n",
       "      <td>1.149780e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.403864e+05</td>\n",
       "      <td>2.866950e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.056228e+04</td>\n",
       "      <td>3.854184e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.034500e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.410100e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.110280e+05</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.788540e+05</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User-ID   Book-Rating\n",
       "count  1.149780e+06  1.149780e+06\n",
       "mean   1.403864e+05  2.866950e+00\n",
       "std    8.056228e+04  3.854184e+00\n",
       "min    2.000000e+00  0.000000e+00\n",
       "25%    7.034500e+04  0.000000e+00\n",
       "50%    1.410100e+05  0.000000e+00\n",
       "75%    2.110280e+05  7.000000e+00\n",
       "max    2.788540e+05  1.000000e+01"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea19fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User-ID        0\n",
       "ISBN           0\n",
       "Book-Rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91355fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105283"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings[\"User-ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cb0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340556"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings[\"ISBN\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949b67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149780, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b6fe1",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1020136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books_cleaned = df_books.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8ac9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271353, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dfbc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_cleaned_user = df_ratings[(df_ratings[\"User-ID\"] >= 1) & (df_ratings[\"User-ID\"] <= 278858)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbf67f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149780, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_cleaned_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffed445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_isbns = set(df_books_cleaned.ISBN)\n",
    "df_ratings_cleaned_books = df_ratings_cleaned_user[df_ratings_cleaned_user[\"ISBN\"].isin(valid_isbns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08577034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1031128, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_cleaned_books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_cleaned_books.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78a33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>276733</td>\n",
       "      <td>2080674722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>276744</td>\n",
       "      <td>038550120X</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>276746</td>\n",
       "      <td>0425115801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>276746</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>276746</td>\n",
       "      <td>0553561618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6\n",
       "5   276733  2080674722            0\n",
       "6   276744  038550120X            7\n",
       "7   276746  0425115801            0\n",
       "8   276746  0449006522            0\n",
       "9   276746  0553561618            0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_cleaned_books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb833c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book-Rating\n",
       "0     647291\n",
       "8      91803\n",
       "10     71224\n",
       "7      66401\n",
       "9      60776\n",
       "5      45355\n",
       "6      31687\n",
       "4       7617\n",
       "3       5118\n",
       "2       2375\n",
       "1       1481\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_cleaned_books[\"Book-Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726c133",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e7f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "author_encoder_dir = os.path.join(\"data\", \"books\", \"processed\", \"author_encoder.json\")\n",
    "publisher_encoder_dir = os.path.join(\"data\", \"books\", \"processed\", \"publisher_encoder.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50597408",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(author_encoder_dir) as f:\n",
    "    author_tokenizer = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68545598",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(author_encoder_dir, \"w\") as f:\n",
    "    json.dump(author_tokenizer, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21a65073",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(publisher_encoder_dir) as f:\n",
    "    publisher_encoder = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9830c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(publisher_encoder_dir, \"w\") as f:\n",
    "    json.dump(publisher_encoder, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "072390cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0ba2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(os.path.join(\"data\", \"books\", \"processed\", \"graph.pt\"), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22ff665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method HeteroData.node_items of HeteroData(\n",
       "  user={ x=[278858, 384] },\n",
       "  book={ x=[271356, 387] },\n",
       "  (user, rates, book)={\n",
       "    edge_index=[2, 1031132],\n",
       "    edge_attr=[1031132, 1],\n",
       "  },\n",
       "  (book, rev_rates, user)={\n",
       "    edge_index=[2, 1031132],\n",
       "    edge_attr=[1031132, 1],\n",
       "  }\n",
       ")>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.node_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02739b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"user\"].x.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff71386",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_transform = RandomLinkSplit(\n",
    "    num_val=0.2, \n",
    "    num_test=0.1, \n",
    "    is_undirected=False, \n",
    "    add_negative_train_samples=True, \n",
    "    neg_sampling_ratio=1.0,\n",
    "    edge_types=[(\"user\", \"rates\", \"book\")],\n",
    "    rev_edge_types=[(\"book\", \"rev_rates\", \"user\")]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36589855",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83b75d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.hetero_data.HeteroData"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0cfca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = LinkNeighborLoader(\n",
    "    train,                                      # Train data\n",
    "    edge_label_index=(\"user\", \"rates\", \"book\"), # Used for sampling the edges in a batch\n",
    "    num_neighbors={                             # Neighbour sampling criteria\n",
    "        (\"user\", \"rates\", \"book\"): [10, 10, 10],\n",
    "        (\"book\", \"rev_rates\", \"user\"): [10, 10, 10]\n",
    "    },\n",
    "    batch_size=4096,                            # Number of edges to select in a batch\n",
    "    shuffle=True                                # Shuffling edges\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "688d0444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b181a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 4096\n",
      "tensor([[ 155, 2467, 2571,  ...,  419,  515,  153],\n",
      "        [1792,  697, 1607,  ...,  433,  945, 1780]])\n",
      "tensor([ 155, 2467, 2571,  ...,  419,  515,  153]) tensor([1792,  697, 1607,  ...,  433,  945, 1780])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    edge_label_index = batch[(\"user\", \"rates\", \"book\")].edge_label_index\n",
    "    user_idx, book_idx = edge_label_index\n",
    "    print(len(user_idx), len(book_idx))\n",
    "    print(edge_label_index)\n",
    "    print(user_idx, book_idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9517991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict = {ntype: data[ntype].x for ntype in data.node_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acc44ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1397, -0.0587,  0.0500,  ..., -0.0511, -0.0218,  0.0576],\n",
       "        [ 0.1021, -0.0035, -0.0734,  ..., -0.0033,  0.0481,  0.0693],\n",
       "        [ 0.0464,  0.0170, -0.0566,  ..., -0.0160, -0.0526, -0.0423],\n",
       "        ...,\n",
       "        [ 0.0159, -0.0044,  0.0020,  ..., -0.0326,  0.0167,  0.0328],\n",
       "        [ 0.0228, -0.0321,  0.0312,  ...,  0.0540, -0.0238, -0.0140],\n",
       "        [ 0.0601, -0.0011,  0.0112,  ..., -0.0253, -0.0271, -0.0007]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dict[\"user\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7889195",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_dict = {etype: data[etype].edge_index for etype in data.edge_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a7f775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('user',\n",
       "  'rates',\n",
       "  'book'): tensor([[276724, 276725, 276726,  ..., 276705, 276708, 276720],\n",
       "         [  2966, 225812,  11053,  ...,  52540,  15978,  56814]]),\n",
       " ('book',\n",
       "  'rev_rates',\n",
       "  'user'): tensor([[  2966, 225812,  11053,  ...,  52540,  15978,  56814],\n",
       "         [276724, 276725, 276726,  ..., 276705, 276708, 276720]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be76d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92f91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Recommender({\"user\": 384, \"book\": 387, \"hidden\": 512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02c5aa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recommender(\n",
       "  (user_proj): NodeEmbedding(\n",
       "    (proj_feats): Linear(in_features=384, out_features=512, bias=True)\n",
       "  )\n",
       "  (book_proj): NodeEmbedding(\n",
       "    (proj_feats): Linear(in_features=387, out_features=512, bias=True)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0-2): 3 x ConvLayer(\n",
       "      (conv): HeteroConv(num_relations=2)\n",
       "      (act): ReLU()\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (user_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (book_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d73d349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book': tensor([[ 2.1190,  0.6166, -0.6380,  ..., -0.6380, -0.5081, -0.6380],\n",
       "         [-0.6227,  0.7638, -0.6227,  ..., -0.6227, -0.6227, -0.6227],\n",
       "         [-0.6336,  2.8947, -0.6336,  ...,  0.8550, -0.1510, -0.6336],\n",
       "         ...,\n",
       "         [-0.5957, -0.3224, -0.5957,  ..., -0.5957, -0.5957, -0.5957],\n",
       "         [-0.3239, -0.6058, -0.6058,  ..., -0.6058, -0.6058, -0.6058],\n",
       "         [ 0.5065, -0.6060, -0.6060,  ..., -0.6060, -0.6060, -0.6060]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " 'user': tensor([[-0.6139,  0.6807, -0.6139,  ..., -0.6139,  1.3009,  0.1775],\n",
       "         [-0.5627,  0.2070, -0.5627,  ..., -0.5627,  1.2797, -0.5627],\n",
       "         [-0.5585,  1.1369,  1.4250,  ...,  2.1811,  1.5007,  0.1663],\n",
       "         ...,\n",
       "         [-0.6259,  0.9237,  2.5051,  ...,  2.9983,  1.1399, -0.6259],\n",
       "         [-0.6070,  0.9619,  1.8968,  ...,  2.1691, -0.6070, -0.1727],\n",
       "         [-0.6221,  0.4788,  1.4704,  ...,  1.7801,  0.9404,  0.0173]],\n",
       "        grad_fn=<NativeLayerNormBackward0>)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "857edd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor((1, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aaebb250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2573dd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0001\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "print(f\"a{a:04}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dfd7b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a03fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(os.getcwd(), \"models\", \"recommender_02.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b23015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('user_proj.proj_feats.weight',\n",
       "              tensor([[-0.0364, -0.0060, -0.0283,  ..., -0.0287,  0.0537,  0.0362],\n",
       "                      [ 0.0230, -0.0384, -0.0032,  ...,  0.0388, -0.0186, -0.0216],\n",
       "                      [-0.0007, -0.0397, -0.0305,  ..., -0.0363, -0.0059,  0.0264],\n",
       "                      ...,\n",
       "                      [ 0.0099,  0.0363,  0.0057,  ..., -0.0355, -0.0150,  0.0007],\n",
       "                      [-0.0275,  0.0005,  0.0200,  ...,  0.0385, -0.0073, -0.0129],\n",
       "                      [-0.0401,  0.0376, -0.0454,  ...,  0.0184, -0.0066,  0.0160]],\n",
       "                     device='cuda:0')),\n",
       "             ('user_proj.proj_feats.bias',\n",
       "              tensor([ 0.0156,  0.0323,  0.0334, -0.0195, -0.0514,  0.0159,  0.0427,  0.0319,\n",
       "                       0.0159,  0.0031, -0.0306, -0.0080, -0.0360, -0.0215, -0.0268, -0.0366,\n",
       "                      -0.0225,  0.0001, -0.0199,  0.0547, -0.0375,  0.0051,  0.0039, -0.0235,\n",
       "                      -0.0455, -0.0344,  0.0101, -0.0545, -0.0139,  0.0131, -0.0040, -0.0217,\n",
       "                       0.0383, -0.0512, -0.0359, -0.0386, -0.0227, -0.0096,  0.0183, -0.0567,\n",
       "                      -0.0372,  0.0312,  0.0016,  0.0040,  0.0167,  0.0262, -0.0163,  0.0334,\n",
       "                       0.0097, -0.0046, -0.0399,  0.0323,  0.0087,  0.0403,  0.0473,  0.0173,\n",
       "                       0.0032, -0.0176,  0.0015,  0.0366,  0.0280,  0.0347,  0.0394, -0.0155,\n",
       "                       0.0464, -0.0312,  0.0362,  0.0333,  0.0123,  0.0118, -0.0006,  0.0024,\n",
       "                       0.0343,  0.0162, -0.0437, -0.0256,  0.0370,  0.0413,  0.0011,  0.0468,\n",
       "                       0.0124, -0.0056,  0.0008,  0.0281,  0.0235, -0.0359,  0.0313, -0.0233,\n",
       "                      -0.0227,  0.0327, -0.0146,  0.0333,  0.0375,  0.0198,  0.0382, -0.0455,\n",
       "                      -0.0249,  0.0279, -0.0439, -0.0037,  0.0300,  0.0514,  0.0182,  0.0089,\n",
       "                      -0.0044,  0.0363, -0.0433, -0.0401, -0.0128, -0.0277,  0.0267, -0.0176,\n",
       "                      -0.0425,  0.0009, -0.0263, -0.0526, -0.0308,  0.0380,  0.0417,  0.0059,\n",
       "                       0.0075,  0.0080, -0.0079,  0.0107, -0.0385, -0.0433,  0.0151, -0.0239,\n",
       "                      -0.0370, -0.0407, -0.0039,  0.0072,  0.0137, -0.0223,  0.0412,  0.0478,\n",
       "                       0.0172,  0.0375, -0.0209,  0.0501, -0.0305,  0.0245,  0.0357,  0.0461,\n",
       "                      -0.0253, -0.0189, -0.0550, -0.0052, -0.0421, -0.0217,  0.0208, -0.0318,\n",
       "                       0.0210,  0.0280,  0.0143,  0.0080,  0.0184,  0.0225, -0.0013, -0.0316,\n",
       "                      -0.0161, -0.0051,  0.0421,  0.0115, -0.0353, -0.0143,  0.0169, -0.0431,\n",
       "                      -0.0165,  0.0304,  0.0267,  0.0499,  0.0240,  0.0159,  0.0388, -0.0448,\n",
       "                       0.0020, -0.0265, -0.0033, -0.0217, -0.0124,  0.0076, -0.0144, -0.0134,\n",
       "                      -0.0432, -0.0377,  0.0156,  0.0077, -0.0350, -0.0226,  0.0123,  0.0417,\n",
       "                      -0.0311,  0.0317,  0.0090, -0.0243,  0.0042,  0.0048, -0.0338,  0.0057,\n",
       "                      -0.0219,  0.0048, -0.0415, -0.0251,  0.0003, -0.0373, -0.0460,  0.0061,\n",
       "                       0.0037,  0.0275, -0.0189, -0.0085,  0.0416, -0.0146, -0.0096, -0.0087,\n",
       "                      -0.0427,  0.0144, -0.0151,  0.0383, -0.0434, -0.0413,  0.0445,  0.0403,\n",
       "                       0.0351, -0.0158, -0.0376, -0.0525,  0.0089, -0.0353,  0.0539,  0.0303,\n",
       "                      -0.0333, -0.0590,  0.0304, -0.0164, -0.0463,  0.0336,  0.0424, -0.0315,\n",
       "                      -0.0290, -0.0181,  0.0084, -0.0468,  0.0258, -0.0113, -0.0196,  0.0389,\n",
       "                       0.0343, -0.0188,  0.0037, -0.0035,  0.0221, -0.0123, -0.0382, -0.0374,\n",
       "                      -0.0161,  0.0283, -0.0227, -0.0300,  0.0431,  0.0315, -0.0230,  0.0200,\n",
       "                       0.0330, -0.0163,  0.0062, -0.0463,  0.0211, -0.0524, -0.0309, -0.0076,\n",
       "                      -0.0020, -0.0346,  0.0093, -0.0210, -0.0212,  0.0275, -0.0605,  0.0283,\n",
       "                      -0.0125, -0.0561, -0.0080, -0.0256,  0.0396,  0.0399,  0.0575,  0.0367,\n",
       "                       0.0081, -0.0199, -0.0102,  0.0545,  0.0046,  0.0331, -0.0175,  0.0423,\n",
       "                      -0.0099, -0.0518,  0.0396, -0.0227, -0.0366,  0.0222, -0.0222,  0.0026,\n",
       "                      -0.0271,  0.0231, -0.0767, -0.0173, -0.0390,  0.0336,  0.0464,  0.0051,\n",
       "                      -0.0183, -0.0405, -0.0296,  0.0325, -0.0021,  0.0108,  0.0053,  0.0380,\n",
       "                      -0.0268,  0.0373,  0.0454, -0.0414,  0.0361, -0.0408, -0.0270, -0.0505,\n",
       "                       0.0455, -0.0425,  0.0137, -0.0354, -0.0145, -0.0397,  0.0187,  0.0137,\n",
       "                      -0.0151,  0.0264, -0.0353, -0.0013,  0.0170,  0.0241,  0.0203,  0.0103,\n",
       "                       0.0151,  0.0358,  0.0389, -0.0404, -0.0013, -0.0243,  0.0463, -0.0121,\n",
       "                       0.0559,  0.0224,  0.0116,  0.0492,  0.0489,  0.0184, -0.0461, -0.0250,\n",
       "                      -0.0478,  0.0048,  0.0364, -0.0179,  0.0336,  0.0072,  0.0381, -0.0085,\n",
       "                      -0.0245, -0.0400,  0.0240,  0.0260, -0.0023, -0.0380,  0.0313, -0.0115,\n",
       "                      -0.0024, -0.0206, -0.0076,  0.0142, -0.0207, -0.0293, -0.0160, -0.0276,\n",
       "                      -0.0007,  0.0427, -0.0302,  0.0408, -0.0207, -0.0009, -0.0556, -0.0369,\n",
       "                      -0.0321, -0.0570,  0.0191,  0.0155, -0.0381, -0.0261,  0.0202,  0.0036,\n",
       "                      -0.0010,  0.0379,  0.0224, -0.0292, -0.0119, -0.0135,  0.0407,  0.0159,\n",
       "                       0.0437,  0.0275,  0.0098,  0.0006, -0.0177, -0.0158, -0.0074, -0.0064,\n",
       "                      -0.0188,  0.0370, -0.0333,  0.0396, -0.0096, -0.0167,  0.0377, -0.0156,\n",
       "                       0.0533,  0.0063, -0.0330, -0.0134,  0.0162, -0.0260, -0.0517,  0.0438,\n",
       "                       0.0266,  0.0040,  0.0548,  0.0367, -0.0416,  0.0011,  0.0408, -0.0465,\n",
       "                       0.0188,  0.0088, -0.0292,  0.0250, -0.0138, -0.0200, -0.0237, -0.0236,\n",
       "                      -0.0263, -0.0157,  0.0235,  0.0183,  0.0337, -0.0202,  0.0165,  0.0460,\n",
       "                       0.0195, -0.0094,  0.0487,  0.0365, -0.0185, -0.0217,  0.0116,  0.0152,\n",
       "                       0.0069, -0.0105,  0.0221, -0.0305, -0.0447, -0.0409,  0.0176,  0.0166,\n",
       "                      -0.0104,  0.0235,  0.0197, -0.0216, -0.0299,  0.0219, -0.0173,  0.0441,\n",
       "                       0.0026, -0.0220,  0.0352, -0.0185,  0.0530,  0.0418, -0.0194,  0.0368,\n",
       "                       0.0376, -0.0042, -0.0511, -0.0290,  0.0216, -0.0257,  0.0068,  0.0387,\n",
       "                      -0.0554, -0.0325,  0.0096,  0.0145,  0.0330,  0.0379, -0.0379,  0.0030,\n",
       "                       0.0067,  0.0361, -0.0072,  0.0324,  0.0453, -0.0435,  0.0208, -0.0008],\n",
       "                     device='cuda:0')),\n",
       "             ('book_proj.proj_feats.weight',\n",
       "              tensor([[-0.0054,  0.0191,  0.0155,  ...,  0.0001,  0.0004, -0.0003],\n",
       "                      [ 0.0358, -0.0110, -0.0132,  ..., -0.0004, -0.0005,  0.0002],\n",
       "                      [-0.0128,  0.0457,  0.0250,  ...,  0.0002,  0.0006, -0.0006],\n",
       "                      ...,\n",
       "                      [-0.0260,  0.0490, -0.0486,  ..., -0.0002, -0.0002,  0.0003],\n",
       "                      [-0.0002,  0.0205, -0.0530,  ..., -0.0007, -0.0009,  0.0003],\n",
       "                      [-0.0168, -0.0424,  0.0277,  ...,  0.0002,  0.0002,  0.0001]],\n",
       "                     device='cuda:0')),\n",
       "             ('book_proj.proj_feats.bias',\n",
       "              tensor([ 1.9509e-02, -1.3156e-03,  3.0524e-03, -2.9570e-02, -8.5908e-04,\n",
       "                       2.2263e-02,  9.1125e-03,  3.5735e-02, -2.3112e-02,  4.3532e-02,\n",
       "                       4.0063e-02, -5.4088e-02, -3.4236e-02,  4.6818e-02, -1.9509e-02,\n",
       "                       9.7332e-03, -2.7077e-02, -4.0453e-02, -2.0522e-02,  1.5558e-02,\n",
       "                      -1.6618e-02, -4.7385e-03, -5.8626e-02, -2.4340e-02,  1.1600e-02,\n",
       "                      -9.5092e-03,  4.0365e-02, -1.3068e-02,  1.3788e-02, -2.3578e-02,\n",
       "                      -3.6538e-02, -5.6356e-02,  5.4309e-02, -4.6574e-02, -1.4532e-02,\n",
       "                      -2.0646e-02,  2.6433e-02,  1.3229e-02,  3.6044e-03, -1.6316e-02,\n",
       "                      -2.1254e-02, -2.0614e-02,  4.2149e-02, -1.1321e-02,  5.9539e-02,\n",
       "                      -1.0722e-03,  3.6271e-02, -5.6307e-02,  3.5369e-03,  2.6778e-02,\n",
       "                       1.4634e-02, -1.9037e-02, -4.1771e-02,  4.8892e-02, -1.0479e-02,\n",
       "                      -9.1768e-03,  2.0198e-02,  2.0047e-02,  2.2961e-02, -3.9985e-02,\n",
       "                      -2.2618e-02, -3.3467e-02, -9.6958e-03,  1.7384e-02,  2.4808e-02,\n",
       "                      -2.0442e-02,  8.9685e-03, -5.9331e-03,  5.1440e-03, -3.2747e-02,\n",
       "                       1.5031e-02, -1.7472e-02, -1.5935e-02, -1.5770e-02,  3.3725e-02,\n",
       "                       5.0058e-02,  3.5998e-02,  3.0209e-02, -3.4918e-02,  1.8061e-02,\n",
       "                      -8.5871e-03, -1.1904e-02, -3.1720e-02, -3.7727e-02,  7.8700e-03,\n",
       "                      -2.1071e-02, -1.4197e-02,  1.1459e-02,  1.3085e-02, -2.6517e-02,\n",
       "                      -4.1867e-02,  3.5735e-03,  1.2945e-02, -1.7162e-02, -6.2892e-04,\n",
       "                       3.7157e-02, -4.6851e-02,  1.3512e-03, -2.4231e-02,  2.2791e-03,\n",
       "                      -2.0746e-03, -2.4818e-02, -3.4843e-02, -1.2393e-02, -2.7397e-02,\n",
       "                       4.0814e-02, -9.5124e-03, -4.4693e-02,  3.3171e-02, -1.6445e-03,\n",
       "                      -7.1084e-02,  6.1938e-02,  3.0867e-02,  7.5981e-04,  1.8133e-02,\n",
       "                      -3.0128e-02,  8.2318e-03,  2.8652e-02, -6.6765e-03,  4.0216e-02,\n",
       "                      -4.8500e-02,  2.6760e-02, -4.6870e-02, -4.5446e-02, -1.3432e-02,\n",
       "                      -2.6860e-02,  5.0950e-02,  2.2286e-03,  2.9840e-02, -5.6966e-03,\n",
       "                      -2.6601e-02, -1.3793e-02, -3.7244e-02, -1.2088e-03, -5.6726e-02,\n",
       "                       3.0863e-02, -2.3345e-02, -6.3632e-03, -2.6956e-02, -6.0524e-02,\n",
       "                      -3.9672e-02, -5.1837e-02, -9.0323e-03,  4.5010e-02, -4.3838e-03,\n",
       "                      -1.0940e-02, -2.6639e-03,  6.9406e-02, -6.2850e-02, -3.3154e-02,\n",
       "                       1.1877e-02,  2.8834e-02, -4.5025e-02, -1.1870e-02, -4.1798e-02,\n",
       "                      -6.5512e-02, -3.0982e-02,  3.7561e-02, -8.3872e-03, -1.8845e-02,\n",
       "                       5.5650e-02, -3.0494e-02, -2.2315e-04, -2.1504e-02, -5.0388e-02,\n",
       "                       3.1579e-02, -1.5340e-02,  2.3686e-02,  1.5770e-03,  4.6986e-02,\n",
       "                      -3.6790e-02,  3.6831e-02,  6.3280e-03,  1.5262e-02, -3.0193e-02,\n",
       "                       4.1309e-02,  2.9954e-02,  5.0602e-03,  2.6615e-02, -3.3457e-02,\n",
       "                      -4.5254e-02,  6.2049e-03,  3.2235e-03,  5.4262e-03,  3.3970e-02,\n",
       "                      -3.7760e-02,  5.2447e-03, -2.2663e-02, -2.1382e-02,  2.3823e-02,\n",
       "                       4.6037e-02, -5.2309e-02,  4.9802e-02, -2.7310e-02, -3.4809e-03,\n",
       "                       1.9189e-03, -1.4999e-02,  1.0668e-02, -6.1185e-02, -6.3547e-02,\n",
       "                       5.0405e-02, -3.2753e-02, -4.2987e-02,  8.1569e-03, -3.4921e-02,\n",
       "                       2.7331e-02, -1.8666e-02,  4.2256e-02, -4.2334e-02,  2.6344e-03,\n",
       "                       1.2374e-02, -1.9342e-02, -5.0248e-02,  2.0527e-02, -2.4506e-02,\n",
       "                      -1.0587e-02,  1.2320e-03,  4.8576e-03,  1.4068e-03, -7.4090e-03,\n",
       "                       1.5366e-02, -2.4449e-02, -3.9646e-02, -4.2868e-04,  2.5332e-02,\n",
       "                       1.0773e-02, -2.2254e-02,  5.4711e-03,  3.7786e-03,  1.4799e-02,\n",
       "                      -3.8511e-02,  5.3686e-03, -1.3386e-02, -1.7178e-02,  8.8162e-03,\n",
       "                      -4.3149e-04, -1.0964e-02, -1.9716e-05,  3.0415e-03,  1.2575e-02,\n",
       "                       4.4129e-02,  9.6494e-03, -4.9908e-02,  2.0181e-02, -8.0882e-04,\n",
       "                       2.6705e-02,  2.7268e-02,  2.7403e-03, -2.0173e-02,  3.4172e-02,\n",
       "                       1.5987e-02, -2.7561e-02, -2.9917e-02, -7.0024e-02,  1.2838e-02,\n",
       "                       9.2848e-03,  7.0321e-03, -1.7766e-03,  4.3360e-02,  1.3034e-02,\n",
       "                       1.2997e-02,  1.4742e-02,  1.9781e-02, -3.7700e-02, -2.6202e-02,\n",
       "                       7.1640e-02,  1.3737e-02,  2.0869e-02,  1.2587e-02,  4.3006e-05,\n",
       "                      -2.8545e-03, -3.2827e-02,  1.3452e-02,  5.3852e-02, -1.3555e-02,\n",
       "                      -5.7780e-02, -4.9057e-02,  3.6310e-03,  1.6357e-02,  4.9884e-02,\n",
       "                       2.7210e-02, -1.3096e-02,  6.1208e-03, -1.0240e-02, -2.9503e-02,\n",
       "                      -6.2254e-03, -2.9679e-02, -2.3022e-02, -4.5469e-02,  5.2877e-05,\n",
       "                      -1.1653e-02,  2.8271e-02,  5.0230e-02,  2.0951e-02,  6.3467e-02,\n",
       "                       4.3902e-03,  1.1989e-02, -3.2450e-02,  5.5961e-02,  3.8971e-02,\n",
       "                      -3.2017e-02,  1.1942e-02, -1.6541e-02,  1.2235e-02,  1.7878e-02,\n",
       "                      -2.9385e-02,  4.0853e-02, -4.0646e-02, -4.9319e-02,  2.3102e-02,\n",
       "                      -2.2943e-02, -3.2297e-02, -3.9150e-02,  4.4651e-02,  5.9187e-03,\n",
       "                       2.2623e-02,  4.2314e-02,  5.1423e-02,  1.6390e-02,  5.9374e-02,\n",
       "                       3.8931e-02, -6.9922e-03, -2.1800e-02,  1.6386e-02, -6.0445e-02,\n",
       "                       5.7811e-02,  1.7441e-03, -1.9704e-02, -4.7000e-02, -3.0457e-02,\n",
       "                       1.5548e-02,  1.6043e-02,  2.6695e-02, -2.6040e-02,  2.9409e-02,\n",
       "                       1.6030e-02, -2.7154e-02, -5.1706e-02,  3.4807e-02,  2.6260e-03,\n",
       "                      -3.8283e-02, -1.5633e-02, -2.1779e-02,  4.6932e-02,  4.7587e-02,\n",
       "                      -1.0769e-02, -5.2588e-02,  5.2091e-02,  4.3857e-02,  4.8451e-02,\n",
       "                      -2.6427e-02,  4.8515e-03, -2.6913e-02, -3.3419e-02,  2.5643e-02,\n",
       "                      -2.8105e-03, -1.3413e-02,  1.5158e-03,  7.1670e-03,  1.6170e-02,\n",
       "                      -6.3493e-02, -3.8031e-02, -4.5527e-02,  2.7339e-02, -6.8375e-03,\n",
       "                       4.1433e-02,  2.8454e-03, -3.3004e-02, -2.0249e-02, -1.5850e-03,\n",
       "                       2.2031e-02, -2.9214e-02, -1.6400e-02,  2.2368e-02,  1.4056e-02,\n",
       "                      -4.0301e-02, -4.4444e-03, -1.4971e-03, -2.8533e-02,  6.5308e-02,\n",
       "                      -1.9088e-02, -5.8615e-04, -9.7406e-03, -2.6966e-02, -1.0226e-02,\n",
       "                      -2.9344e-02, -1.7209e-02, -1.8685e-02, -4.2742e-02, -3.4200e-02,\n",
       "                       5.8443e-03,  1.2331e-02,  7.3446e-03, -1.5587e-02,  1.1004e-02,\n",
       "                      -1.0887e-02,  4.0581e-02, -7.4021e-02,  4.8459e-03, -2.5718e-04,\n",
       "                      -4.0669e-02, -3.5284e-04, -4.6416e-04,  7.0659e-03, -1.0325e-02,\n",
       "                      -3.5302e-02,  2.4280e-02, -2.8635e-02, -3.7937e-02, -5.2443e-04,\n",
       "                      -1.2908e-03,  5.9921e-02,  5.5270e-02,  2.2377e-02,  3.6133e-03,\n",
       "                       2.8637e-02,  4.2575e-02, -2.8619e-02, -1.8198e-02, -2.6928e-02,\n",
       "                       3.7779e-02, -3.1093e-03,  7.6455e-03,  2.8900e-02, -1.2346e-02,\n",
       "                      -1.3025e-02,  5.2485e-02, -3.2561e-02, -1.3124e-02,  1.9708e-02,\n",
       "                       4.1110e-02,  1.1588e-02, -1.4198e-02, -4.2856e-02,  9.9204e-03,\n",
       "                       1.2288e-02,  5.0970e-02,  1.2823e-02,  2.6718e-02,  4.8250e-02,\n",
       "                       3.5728e-02,  7.3234e-03, -1.8784e-02,  3.6453e-02, -2.9224e-02,\n",
       "                       3.9064e-02, -3.5292e-02, -3.4692e-02, -2.2342e-03, -1.7042e-03,\n",
       "                       2.0463e-02,  2.9930e-03, -3.0580e-02, -4.8279e-02, -9.2691e-04,\n",
       "                       3.1125e-02,  2.5544e-02,  3.1313e-02, -4.3839e-03, -7.8282e-03,\n",
       "                      -2.9862e-02, -3.6046e-03, -3.0254e-02, -3.1457e-02, -2.8275e-02,\n",
       "                       2.3259e-02,  5.0013e-02, -3.9857e-02,  1.4489e-02, -3.9497e-03,\n",
       "                      -5.0695e-03, -1.3163e-02,  1.2665e-02, -1.9739e-02,  5.3916e-03,\n",
       "                       3.9515e-04, -3.3485e-02, -1.3579e-02,  1.0334e-02, -4.2506e-02,\n",
       "                       3.3742e-03, -2.1744e-02, -2.6906e-02, -2.4679e-02,  3.2183e-03,\n",
       "                      -6.1707e-02,  2.9415e-02,  1.3104e-02,  4.0571e-02,  3.1950e-02,\n",
       "                      -1.1399e-02, -2.9292e-02, -1.8336e-03, -6.5668e-03, -4.2679e-02,\n",
       "                      -3.9870e-02, -1.5107e-03, -2.8993e-02, -5.8033e-02, -1.9249e-02,\n",
       "                       4.3217e-02, -8.2482e-03, -4.3842e-02, -9.4094e-03, -2.1772e-02,\n",
       "                       4.6332e-04, -2.9075e-03,  1.1004e-02, -3.8299e-02, -5.5127e-03,\n",
       "                       5.7912e-03,  2.6148e-02], device='cuda:0')),\n",
       "             ('layers.0.conv.convs.<user___rates___book>.lin_l.weight',\n",
       "              tensor([[-6.8731e-03,  2.5172e-04, -2.1470e-02,  ...,  1.3695e-02,\n",
       "                       -6.7315e-05,  1.9759e-02],\n",
       "                      [-2.4015e-02,  2.2459e-02, -2.5447e-02,  ..., -3.5139e-02,\n",
       "                       -3.5578e-02, -6.2887e-03],\n",
       "                      [ 1.8746e-05,  3.1661e-03,  7.3770e-03,  ...,  2.2282e-03,\n",
       "                        3.0040e-04, -5.0420e-03],\n",
       "                      ...,\n",
       "                      [ 7.6317e-03,  1.4394e-02,  4.5764e-02,  ...,  9.1861e-03,\n",
       "                        3.2862e-02, -3.8243e-02],\n",
       "                      [ 3.5112e-02, -5.9959e-03, -4.4513e-02,  ..., -3.2488e-02,\n",
       "                       -2.4164e-02,  4.0652e-02],\n",
       "                      [ 1.8848e-02, -2.6800e-02, -2.0564e-02,  ..., -2.5894e-02,\n",
       "                        3.2299e-02, -3.4360e-02]], device='cuda:0')),\n",
       "             ('layers.0.conv.convs.<user___rates___book>.lin_l.bias',\n",
       "              tensor([-1.8447e-02,  3.9102e-02,  3.5496e-02,  4.5970e-02,  2.4430e-02,\n",
       "                       1.4179e-02,  1.3798e-02,  6.3338e-03,  2.7995e-02, -1.8136e-02,\n",
       "                       1.6297e-02, -9.0286e-05,  2.6416e-02, -3.9000e-02, -2.5916e-02,\n",
       "                      -1.1703e-03,  2.8593e-02, -4.8790e-02,  3.3917e-02,  2.0613e-02,\n",
       "                      -3.4519e-02, -4.5973e-03, -2.6377e-02, -7.2906e-04, -3.5990e-03,\n",
       "                       3.6694e-02,  5.5357e-02,  3.1541e-02,  5.7513e-03, -1.9585e-02,\n",
       "                      -1.4545e-02,  9.3659e-03, -2.2673e-03,  2.8269e-02,  3.7339e-02,\n",
       "                       3.5914e-02,  2.7361e-02,  2.3002e-02,  2.9605e-02,  2.3452e-02,\n",
       "                       3.2223e-04,  8.9557e-03,  2.5988e-02, -3.0578e-02,  1.6849e-02,\n",
       "                       5.3644e-03,  4.2053e-02,  2.0740e-02,  1.3253e-02,  3.3997e-02,\n",
       "                       9.6416e-03, -2.6026e-02,  2.3373e-02, -3.4915e-03,  2.7496e-02,\n",
       "                       9.7701e-04, -5.4511e-03, -2.8673e-03, -7.2569e-03, -3.1131e-02,\n",
       "                      -3.7894e-02, -1.0226e-02, -1.9220e-02, -2.3572e-02,  3.3425e-02,\n",
       "                       1.5187e-02, -1.6678e-02,  6.2274e-03,  2.0624e-02,  1.0646e-02,\n",
       "                      -4.4239e-03,  6.8302e-03,  2.7818e-02,  4.5785e-02, -3.9909e-02,\n",
       "                      -3.3309e-06,  2.2205e-02, -1.9217e-02, -7.4054e-03, -1.3586e-02,\n",
       "                       2.7616e-02, -2.2097e-02,  3.2980e-02,  3.5621e-02,  1.7781e-02,\n",
       "                      -8.7765e-03,  1.1091e-02,  9.4676e-03, -1.3863e-02, -4.9295e-04,\n",
       "                      -4.2971e-02,  2.4351e-03, -1.8333e-02,  2.8064e-02, -3.9351e-02,\n",
       "                      -3.0980e-02, -2.4445e-02, -1.0140e-02,  4.2773e-02, -1.6141e-02,\n",
       "                       9.4435e-03, -2.1362e-02,  2.4996e-02,  2.6597e-02, -5.5731e-03,\n",
       "                       1.7349e-02,  3.4672e-02,  3.6156e-02, -5.9198e-03, -3.6157e-02,\n",
       "                      -1.8757e-03,  3.7882e-02,  2.4897e-03, -4.2513e-03, -2.7700e-02,\n",
       "                      -2.1312e-03,  2.6417e-02, -2.9946e-02, -1.2301e-02,  8.5486e-04,\n",
       "                      -1.4391e-02,  1.7660e-02,  1.1879e-03,  3.3410e-02, -2.5049e-02,\n",
       "                       4.7667e-02,  2.7000e-02, -2.5238e-02, -1.4190e-03, -6.9856e-03,\n",
       "                       2.4625e-02,  1.8253e-02, -1.8018e-02,  1.0360e-02,  2.6054e-02,\n",
       "                       1.4903e-02,  3.3942e-02, -3.3457e-02, -2.5746e-02, -1.8114e-02,\n",
       "                      -2.8872e-02, -7.5442e-03,  3.1508e-02, -5.6558e-03,  3.3101e-02,\n",
       "                      -2.9231e-02, -3.1207e-02,  2.1878e-02, -2.0202e-03, -3.5127e-02,\n",
       "                       3.0604e-02,  4.2155e-02,  4.6939e-02, -1.4444e-02,  4.7655e-02,\n",
       "                      -3.4885e-02, -3.1898e-02,  4.3418e-02,  2.7302e-02, -2.2017e-02,\n",
       "                       2.6620e-02, -4.2374e-02, -1.7404e-02, -2.3048e-02,  1.9992e-02,\n",
       "                       4.3113e-02, -5.2310e-02,  8.7603e-03, -8.9825e-03,  4.0820e-02,\n",
       "                      -3.1576e-02, -4.1612e-02, -1.2321e-02, -5.2001e-02, -3.2304e-02,\n",
       "                       1.0754e-02,  8.6741e-03,  1.0810e-02,  9.4889e-03,  5.1054e-03,\n",
       "                      -1.6828e-02,  1.3133e-02,  7.2271e-03, -4.9228e-02, -1.7626e-02,\n",
       "                      -9.7511e-03,  1.6470e-02,  4.5901e-03,  1.1267e-02,  1.0421e-04,\n",
       "                      -2.6408e-03,  1.5769e-02,  3.9658e-03, -2.4498e-02, -1.0129e-02,\n",
       "                      -1.7967e-02, -4.7680e-02,  4.7071e-02, -2.1785e-02, -2.2947e-02,\n",
       "                       1.3167e-02, -1.3566e-02,  6.8083e-03, -1.7566e-02,  1.9288e-02,\n",
       "                      -1.7486e-02, -3.3895e-02,  2.8884e-02,  1.9729e-04, -6.4065e-03,\n",
       "                      -2.2028e-02,  3.5620e-02, -1.6715e-02, -1.0461e-02,  4.1800e-02,\n",
       "                       1.6906e-02,  3.2426e-02,  2.6926e-02,  7.3273e-03,  9.2327e-03,\n",
       "                       9.6496e-03,  1.0570e-02,  4.0931e-02,  8.5560e-03,  9.0532e-03,\n",
       "                      -3.2980e-02, -1.6146e-02, -3.3712e-02,  1.4972e-02,  1.5815e-02,\n",
       "                      -1.8229e-04,  8.4163e-03, -4.5133e-02, -4.4179e-02,  7.0197e-03,\n",
       "                      -1.6857e-03, -3.3692e-02, -2.4353e-02,  1.1210e-02,  1.6522e-02,\n",
       "                      -1.1073e-02, -3.1098e-02,  2.9688e-02, -1.6742e-02,  9.2897e-03,\n",
       "                      -4.4014e-02,  7.9615e-03, -6.4578e-03, -3.5632e-03,  3.2597e-02,\n",
       "                       1.6636e-02, -4.9830e-03, -4.7768e-02, -1.8737e-02,  1.3355e-02,\n",
       "                      -2.0212e-02, -4.0303e-03, -5.0860e-03,  1.8465e-02,  2.4584e-02,\n",
       "                       1.0228e-02, -2.2359e-02, -2.4139e-02,  2.4947e-02, -2.0213e-02,\n",
       "                       4.9524e-03, -2.0504e-02,  2.7165e-02,  1.2328e-02, -2.2203e-02,\n",
       "                       2.4840e-02,  9.8585e-03,  3.1214e-02,  1.1528e-02, -3.9495e-02,\n",
       "                       1.3437e-02, -1.5149e-02,  2.5931e-02,  1.8546e-02,  1.5404e-02,\n",
       "                      -4.7768e-03, -1.8569e-02,  5.0921e-03,  3.2942e-02,  1.3159e-02,\n",
       "                       3.1182e-02, -9.6976e-03,  3.0952e-02, -1.4752e-02, -5.7218e-03,\n",
       "                       2.1544e-02,  3.3339e-02,  1.7089e-02,  4.9219e-02,  2.3558e-03,\n",
       "                       2.6669e-02, -1.2811e-02,  2.3070e-02, -3.6529e-02,  3.3419e-02,\n",
       "                      -3.6432e-02, -1.4431e-02,  1.4298e-02,  2.0403e-02,  1.9942e-02,\n",
       "                       2.3402e-02, -9.0303e-03, -7.1634e-03,  1.8869e-02,  1.4642e-02,\n",
       "                       6.7115e-03, -2.3083e-02,  3.3550e-02, -3.4992e-02,  3.0088e-02,\n",
       "                      -2.1387e-02,  1.0375e-02, -2.4739e-02,  2.8343e-02,  3.7800e-03,\n",
       "                      -1.1453e-02, -1.8674e-02, -1.7157e-02, -1.8753e-02, -3.4677e-02,\n",
       "                       4.8730e-02,  8.3820e-03, -1.6365e-02, -2.2421e-02,  1.1320e-02,\n",
       "                       9.0791e-03,  4.6773e-02, -2.1351e-02,  2.7560e-02, -1.8298e-02,\n",
       "                       1.7821e-02, -3.3806e-02, -2.1218e-02, -3.0964e-02,  2.0133e-02,\n",
       "                      -9.3623e-03,  3.0370e-02,  4.1724e-02, -2.3597e-03, -1.2094e-02,\n",
       "                      -3.2521e-02, -3.7735e-02, -2.5160e-02, -1.8238e-02,  4.5476e-03,\n",
       "                      -4.9589e-04, -1.1048e-02, -2.3890e-03,  2.6285e-02, -1.5896e-02,\n",
       "                      -1.6334e-02, -5.8423e-03, -3.5540e-02, -3.1153e-02, -2.9063e-02,\n",
       "                       2.7697e-02, -5.4432e-03, -1.5649e-02,  2.5614e-02,  3.7263e-02,\n",
       "                      -4.8235e-03,  3.1946e-02,  1.7956e-02,  1.8240e-02,  4.2825e-03,\n",
       "                      -5.8658e-04, -3.0752e-02, -1.0782e-02,  4.1158e-02,  4.8568e-03,\n",
       "                       4.3360e-02, -2.7176e-02,  1.7982e-02,  2.5416e-02,  2.1095e-02,\n",
       "                       3.4172e-02,  1.2577e-02, -2.6597e-03, -1.1245e-02, -1.5373e-02,\n",
       "                       1.5180e-02,  4.5446e-02, -8.7018e-03,  7.1664e-03, -3.7817e-03,\n",
       "                       2.2257e-02, -3.3984e-03, -2.1976e-02,  1.5398e-02, -3.1056e-02,\n",
       "                      -1.4681e-02, -3.1751e-02, -2.7724e-02, -1.3357e-02, -1.6455e-02,\n",
       "                      -1.4922e-02,  2.6512e-03,  3.7688e-02,  4.9555e-02,  3.5404e-02,\n",
       "                       3.4633e-02,  8.9569e-03, -4.4723e-02, -3.4248e-02, -1.3280e-03,\n",
       "                       3.8340e-04,  2.2634e-02, -3.1368e-02,  3.4025e-02,  2.1252e-04,\n",
       "                       7.2062e-03, -3.4567e-02, -1.9208e-02, -7.0301e-03, -3.6756e-02,\n",
       "                       3.6749e-03, -3.8990e-02, -5.8859e-02,  1.8154e-02, -3.2701e-02,\n",
       "                      -2.1375e-02, -7.6244e-03,  2.9840e-02,  4.6688e-02,  4.8734e-03,\n",
       "                       1.5695e-02, -4.7476e-03, -1.5085e-02,  1.5795e-03,  4.1807e-02,\n",
       "                      -3.2733e-02,  2.1333e-02,  4.3840e-04, -3.6619e-02, -3.6067e-02,\n",
       "                      -1.9919e-02, -3.5818e-02, -2.8032e-02,  4.9643e-02,  1.9840e-02,\n",
       "                      -4.7171e-02,  3.5674e-02, -2.6109e-02,  3.2774e-02,  3.4215e-02,\n",
       "                       3.1224e-02,  8.1013e-03,  4.7757e-02, -3.1766e-02, -2.8846e-03,\n",
       "                       2.8674e-02,  3.1067e-02, -3.6712e-02, -1.6750e-02,  3.3624e-02,\n",
       "                      -1.3063e-02,  1.1004e-02, -4.4206e-03, -5.0048e-02,  1.3596e-02,\n",
       "                      -9.8446e-03,  5.6965e-03, -2.8856e-03, -4.6701e-02, -3.5046e-02,\n",
       "                      -4.2904e-03, -1.5935e-02, -4.1144e-03,  3.6237e-02,  1.3687e-03,\n",
       "                       3.0327e-02, -3.6525e-02, -1.2821e-02,  4.1777e-02, -1.5930e-02,\n",
       "                       4.0791e-02,  2.1312e-02, -1.3636e-02,  2.6506e-02, -7.0080e-03,\n",
       "                       2.2886e-02, -1.1475e-02,  2.1269e-02, -5.3614e-03,  3.6183e-02,\n",
       "                      -2.4439e-02,  3.6473e-02, -2.3223e-03,  3.1500e-02,  3.7895e-02,\n",
       "                       1.7887e-02,  1.6421e-02,  2.9208e-02, -1.9057e-03,  5.4510e-03,\n",
       "                       1.7456e-02,  3.0026e-02, -4.2354e-02,  4.6317e-02, -2.0388e-03,\n",
       "                       3.1707e-02,  5.3078e-03,  1.9953e-02, -1.3671e-02,  3.2287e-02,\n",
       "                       1.9742e-02, -7.9550e-03], device='cuda:0')),\n",
       "             ('layers.0.conv.convs.<user___rates___book>.lin_r.weight',\n",
       "              tensor([[ 0.0199,  0.0225,  0.0280,  ..., -0.0425, -0.0425, -0.0280],\n",
       "                      [-0.0227, -0.0126, -0.0002,  ...,  0.0329, -0.0299, -0.0376],\n",
       "                      [ 0.0034, -0.0251, -0.0005,  ...,  0.0264, -0.0209,  0.0142],\n",
       "                      ...,\n",
       "                      [ 0.0421,  0.0370,  0.0162,  ..., -0.0377, -0.0013, -0.0222],\n",
       "                      [-0.0010, -0.0329, -0.0257,  ..., -0.0228, -0.0274, -0.0096],\n",
       "                      [ 0.0055, -0.0019,  0.0386,  ...,  0.0385, -0.0407,  0.0097]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.0.conv.convs.<book___rev_rates___user>.lin_l.weight',\n",
       "              tensor([[-6.8731e-03,  2.5172e-04, -2.1470e-02,  ...,  1.3695e-02,\n",
       "                       -6.7315e-05,  1.9759e-02],\n",
       "                      [-2.4015e-02,  2.2459e-02, -2.5447e-02,  ..., -3.5139e-02,\n",
       "                       -3.5578e-02, -6.2887e-03],\n",
       "                      [ 1.8746e-05,  3.1661e-03,  7.3770e-03,  ...,  2.2282e-03,\n",
       "                        3.0040e-04, -5.0420e-03],\n",
       "                      ...,\n",
       "                      [ 7.6317e-03,  1.4394e-02,  4.5764e-02,  ...,  9.1861e-03,\n",
       "                        3.2862e-02, -3.8243e-02],\n",
       "                      [ 3.5112e-02, -5.9959e-03, -4.4513e-02,  ..., -3.2488e-02,\n",
       "                       -2.4164e-02,  4.0652e-02],\n",
       "                      [ 1.8848e-02, -2.6800e-02, -2.0564e-02,  ..., -2.5894e-02,\n",
       "                        3.2299e-02, -3.4360e-02]], device='cuda:0')),\n",
       "             ('layers.0.conv.convs.<book___rev_rates___user>.lin_l.bias',\n",
       "              tensor([-1.8447e-02,  3.9102e-02,  3.5496e-02,  4.5970e-02,  2.4430e-02,\n",
       "                       1.4179e-02,  1.3798e-02,  6.3338e-03,  2.7995e-02, -1.8136e-02,\n",
       "                       1.6297e-02, -9.0286e-05,  2.6416e-02, -3.9000e-02, -2.5916e-02,\n",
       "                      -1.1703e-03,  2.8593e-02, -4.8790e-02,  3.3917e-02,  2.0613e-02,\n",
       "                      -3.4519e-02, -4.5973e-03, -2.6377e-02, -7.2906e-04, -3.5990e-03,\n",
       "                       3.6694e-02,  5.5357e-02,  3.1541e-02,  5.7513e-03, -1.9585e-02,\n",
       "                      -1.4545e-02,  9.3659e-03, -2.2673e-03,  2.8269e-02,  3.7339e-02,\n",
       "                       3.5914e-02,  2.7361e-02,  2.3002e-02,  2.9605e-02,  2.3452e-02,\n",
       "                       3.2223e-04,  8.9557e-03,  2.5988e-02, -3.0578e-02,  1.6849e-02,\n",
       "                       5.3644e-03,  4.2053e-02,  2.0740e-02,  1.3253e-02,  3.3997e-02,\n",
       "                       9.6416e-03, -2.6026e-02,  2.3373e-02, -3.4915e-03,  2.7496e-02,\n",
       "                       9.7701e-04, -5.4511e-03, -2.8673e-03, -7.2569e-03, -3.1131e-02,\n",
       "                      -3.7894e-02, -1.0226e-02, -1.9220e-02, -2.3572e-02,  3.3425e-02,\n",
       "                       1.5187e-02, -1.6678e-02,  6.2274e-03,  2.0624e-02,  1.0646e-02,\n",
       "                      -4.4239e-03,  6.8302e-03,  2.7818e-02,  4.5785e-02, -3.9909e-02,\n",
       "                      -3.3309e-06,  2.2205e-02, -1.9217e-02, -7.4054e-03, -1.3586e-02,\n",
       "                       2.7616e-02, -2.2097e-02,  3.2980e-02,  3.5621e-02,  1.7781e-02,\n",
       "                      -8.7765e-03,  1.1091e-02,  9.4676e-03, -1.3863e-02, -4.9295e-04,\n",
       "                      -4.2971e-02,  2.4351e-03, -1.8333e-02,  2.8064e-02, -3.9351e-02,\n",
       "                      -3.0980e-02, -2.4445e-02, -1.0140e-02,  4.2773e-02, -1.6141e-02,\n",
       "                       9.4435e-03, -2.1362e-02,  2.4996e-02,  2.6597e-02, -5.5731e-03,\n",
       "                       1.7349e-02,  3.4672e-02,  3.6156e-02, -5.9198e-03, -3.6157e-02,\n",
       "                      -1.8757e-03,  3.7882e-02,  2.4897e-03, -4.2513e-03, -2.7700e-02,\n",
       "                      -2.1312e-03,  2.6417e-02, -2.9946e-02, -1.2301e-02,  8.5486e-04,\n",
       "                      -1.4391e-02,  1.7660e-02,  1.1879e-03,  3.3410e-02, -2.5049e-02,\n",
       "                       4.7667e-02,  2.7000e-02, -2.5238e-02, -1.4190e-03, -6.9856e-03,\n",
       "                       2.4625e-02,  1.8253e-02, -1.8018e-02,  1.0360e-02,  2.6054e-02,\n",
       "                       1.4903e-02,  3.3942e-02, -3.3457e-02, -2.5746e-02, -1.8114e-02,\n",
       "                      -2.8872e-02, -7.5442e-03,  3.1508e-02, -5.6558e-03,  3.3101e-02,\n",
       "                      -2.9231e-02, -3.1207e-02,  2.1878e-02, -2.0202e-03, -3.5127e-02,\n",
       "                       3.0604e-02,  4.2155e-02,  4.6939e-02, -1.4444e-02,  4.7655e-02,\n",
       "                      -3.4885e-02, -3.1898e-02,  4.3418e-02,  2.7302e-02, -2.2017e-02,\n",
       "                       2.6620e-02, -4.2374e-02, -1.7404e-02, -2.3048e-02,  1.9992e-02,\n",
       "                       4.3113e-02, -5.2310e-02,  8.7603e-03, -8.9825e-03,  4.0820e-02,\n",
       "                      -3.1576e-02, -4.1612e-02, -1.2321e-02, -5.2001e-02, -3.2304e-02,\n",
       "                       1.0754e-02,  8.6741e-03,  1.0810e-02,  9.4889e-03,  5.1054e-03,\n",
       "                      -1.6828e-02,  1.3133e-02,  7.2271e-03, -4.9228e-02, -1.7626e-02,\n",
       "                      -9.7511e-03,  1.6470e-02,  4.5901e-03,  1.1267e-02,  1.0421e-04,\n",
       "                      -2.6408e-03,  1.5769e-02,  3.9658e-03, -2.4498e-02, -1.0129e-02,\n",
       "                      -1.7967e-02, -4.7680e-02,  4.7071e-02, -2.1785e-02, -2.2947e-02,\n",
       "                       1.3167e-02, -1.3566e-02,  6.8083e-03, -1.7566e-02,  1.9288e-02,\n",
       "                      -1.7486e-02, -3.3895e-02,  2.8884e-02,  1.9729e-04, -6.4065e-03,\n",
       "                      -2.2028e-02,  3.5620e-02, -1.6715e-02, -1.0461e-02,  4.1800e-02,\n",
       "                       1.6906e-02,  3.2426e-02,  2.6926e-02,  7.3273e-03,  9.2327e-03,\n",
       "                       9.6496e-03,  1.0570e-02,  4.0931e-02,  8.5560e-03,  9.0532e-03,\n",
       "                      -3.2980e-02, -1.6146e-02, -3.3712e-02,  1.4972e-02,  1.5815e-02,\n",
       "                      -1.8229e-04,  8.4163e-03, -4.5133e-02, -4.4179e-02,  7.0197e-03,\n",
       "                      -1.6857e-03, -3.3692e-02, -2.4353e-02,  1.1210e-02,  1.6522e-02,\n",
       "                      -1.1073e-02, -3.1098e-02,  2.9688e-02, -1.6742e-02,  9.2897e-03,\n",
       "                      -4.4014e-02,  7.9615e-03, -6.4578e-03, -3.5632e-03,  3.2597e-02,\n",
       "                       1.6636e-02, -4.9830e-03, -4.7768e-02, -1.8737e-02,  1.3355e-02,\n",
       "                      -2.0212e-02, -4.0303e-03, -5.0860e-03,  1.8465e-02,  2.4584e-02,\n",
       "                       1.0228e-02, -2.2359e-02, -2.4139e-02,  2.4947e-02, -2.0213e-02,\n",
       "                       4.9524e-03, -2.0504e-02,  2.7165e-02,  1.2328e-02, -2.2203e-02,\n",
       "                       2.4840e-02,  9.8585e-03,  3.1214e-02,  1.1528e-02, -3.9495e-02,\n",
       "                       1.3437e-02, -1.5149e-02,  2.5931e-02,  1.8546e-02,  1.5404e-02,\n",
       "                      -4.7768e-03, -1.8569e-02,  5.0921e-03,  3.2942e-02,  1.3159e-02,\n",
       "                       3.1182e-02, -9.6976e-03,  3.0952e-02, -1.4752e-02, -5.7218e-03,\n",
       "                       2.1544e-02,  3.3339e-02,  1.7089e-02,  4.9219e-02,  2.3558e-03,\n",
       "                       2.6669e-02, -1.2811e-02,  2.3070e-02, -3.6529e-02,  3.3419e-02,\n",
       "                      -3.6432e-02, -1.4431e-02,  1.4298e-02,  2.0403e-02,  1.9942e-02,\n",
       "                       2.3402e-02, -9.0303e-03, -7.1634e-03,  1.8869e-02,  1.4642e-02,\n",
       "                       6.7115e-03, -2.3083e-02,  3.3550e-02, -3.4992e-02,  3.0088e-02,\n",
       "                      -2.1387e-02,  1.0375e-02, -2.4739e-02,  2.8343e-02,  3.7800e-03,\n",
       "                      -1.1453e-02, -1.8674e-02, -1.7157e-02, -1.8753e-02, -3.4677e-02,\n",
       "                       4.8730e-02,  8.3820e-03, -1.6365e-02, -2.2421e-02,  1.1320e-02,\n",
       "                       9.0791e-03,  4.6773e-02, -2.1351e-02,  2.7560e-02, -1.8298e-02,\n",
       "                       1.7821e-02, -3.3806e-02, -2.1218e-02, -3.0964e-02,  2.0133e-02,\n",
       "                      -9.3623e-03,  3.0370e-02,  4.1724e-02, -2.3597e-03, -1.2094e-02,\n",
       "                      -3.2521e-02, -3.7735e-02, -2.5160e-02, -1.8238e-02,  4.5476e-03,\n",
       "                      -4.9589e-04, -1.1048e-02, -2.3890e-03,  2.6285e-02, -1.5896e-02,\n",
       "                      -1.6334e-02, -5.8423e-03, -3.5540e-02, -3.1153e-02, -2.9063e-02,\n",
       "                       2.7697e-02, -5.4432e-03, -1.5649e-02,  2.5614e-02,  3.7263e-02,\n",
       "                      -4.8235e-03,  3.1946e-02,  1.7956e-02,  1.8240e-02,  4.2825e-03,\n",
       "                      -5.8658e-04, -3.0752e-02, -1.0782e-02,  4.1158e-02,  4.8568e-03,\n",
       "                       4.3360e-02, -2.7176e-02,  1.7982e-02,  2.5416e-02,  2.1095e-02,\n",
       "                       3.4172e-02,  1.2577e-02, -2.6597e-03, -1.1245e-02, -1.5373e-02,\n",
       "                       1.5180e-02,  4.5446e-02, -8.7018e-03,  7.1664e-03, -3.7817e-03,\n",
       "                       2.2257e-02, -3.3984e-03, -2.1976e-02,  1.5398e-02, -3.1056e-02,\n",
       "                      -1.4681e-02, -3.1751e-02, -2.7724e-02, -1.3357e-02, -1.6455e-02,\n",
       "                      -1.4922e-02,  2.6512e-03,  3.7688e-02,  4.9555e-02,  3.5404e-02,\n",
       "                       3.4633e-02,  8.9569e-03, -4.4723e-02, -3.4248e-02, -1.3280e-03,\n",
       "                       3.8340e-04,  2.2634e-02, -3.1368e-02,  3.4025e-02,  2.1252e-04,\n",
       "                       7.2062e-03, -3.4567e-02, -1.9208e-02, -7.0301e-03, -3.6756e-02,\n",
       "                       3.6749e-03, -3.8990e-02, -5.8859e-02,  1.8154e-02, -3.2701e-02,\n",
       "                      -2.1375e-02, -7.6244e-03,  2.9840e-02,  4.6688e-02,  4.8734e-03,\n",
       "                       1.5695e-02, -4.7476e-03, -1.5085e-02,  1.5795e-03,  4.1807e-02,\n",
       "                      -3.2733e-02,  2.1333e-02,  4.3840e-04, -3.6619e-02, -3.6067e-02,\n",
       "                      -1.9919e-02, -3.5818e-02, -2.8032e-02,  4.9643e-02,  1.9840e-02,\n",
       "                      -4.7171e-02,  3.5674e-02, -2.6109e-02,  3.2774e-02,  3.4215e-02,\n",
       "                       3.1224e-02,  8.1013e-03,  4.7757e-02, -3.1766e-02, -2.8846e-03,\n",
       "                       2.8674e-02,  3.1067e-02, -3.6712e-02, -1.6750e-02,  3.3624e-02,\n",
       "                      -1.3063e-02,  1.1004e-02, -4.4206e-03, -5.0048e-02,  1.3596e-02,\n",
       "                      -9.8446e-03,  5.6965e-03, -2.8856e-03, -4.6701e-02, -3.5046e-02,\n",
       "                      -4.2904e-03, -1.5935e-02, -4.1144e-03,  3.6237e-02,  1.3687e-03,\n",
       "                       3.0327e-02, -3.6525e-02, -1.2821e-02,  4.1777e-02, -1.5930e-02,\n",
       "                       4.0791e-02,  2.1312e-02, -1.3636e-02,  2.6506e-02, -7.0080e-03,\n",
       "                       2.2886e-02, -1.1475e-02,  2.1269e-02, -5.3614e-03,  3.6183e-02,\n",
       "                      -2.4439e-02,  3.6473e-02, -2.3223e-03,  3.1500e-02,  3.7895e-02,\n",
       "                       1.7887e-02,  1.6421e-02,  2.9208e-02, -1.9057e-03,  5.4510e-03,\n",
       "                       1.7456e-02,  3.0026e-02, -4.2354e-02,  4.6317e-02, -2.0388e-03,\n",
       "                       3.1707e-02,  5.3078e-03,  1.9953e-02, -1.3671e-02,  3.2287e-02,\n",
       "                       1.9742e-02, -7.9550e-03], device='cuda:0')),\n",
       "             ('layers.0.conv.convs.<book___rev_rates___user>.lin_r.weight',\n",
       "              tensor([[ 0.0199,  0.0225,  0.0280,  ..., -0.0425, -0.0425, -0.0280],\n",
       "                      [-0.0227, -0.0126, -0.0002,  ...,  0.0329, -0.0299, -0.0376],\n",
       "                      [ 0.0034, -0.0251, -0.0005,  ...,  0.0264, -0.0209,  0.0142],\n",
       "                      ...,\n",
       "                      [ 0.0421,  0.0370,  0.0162,  ..., -0.0377, -0.0013, -0.0222],\n",
       "                      [-0.0010, -0.0329, -0.0257,  ..., -0.0228, -0.0274, -0.0096],\n",
       "                      [ 0.0055, -0.0019,  0.0386,  ...,  0.0385, -0.0407,  0.0097]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.1.conv.convs.<user___rates___book>.lin_l.weight',\n",
       "              tensor([[-0.0079, -0.0469,  0.0347,  ...,  0.0340,  0.0028, -0.0023],\n",
       "                      [-0.0223,  0.0023,  0.0320,  ...,  0.0395, -0.0152,  0.0280],\n",
       "                      [ 0.0376,  0.0282,  0.0382,  ..., -0.0201, -0.0412, -0.0450],\n",
       "                      ...,\n",
       "                      [-0.0295, -0.0486, -0.0272,  ..., -0.0206, -0.0106, -0.0101],\n",
       "                      [-0.0323, -0.0123, -0.0207,  ...,  0.0140,  0.0003, -0.0406],\n",
       "                      [ 0.0041, -0.0247,  0.0016,  ..., -0.0063,  0.0445, -0.0189]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.1.conv.convs.<user___rates___book>.lin_l.bias',\n",
       "              tensor([-1.1097e-03, -4.8203e-02,  2.2891e-02, -2.5854e-02, -5.0503e-03,\n",
       "                       1.7734e-02,  2.2911e-02, -1.0490e-02,  3.6572e-02,  1.8520e-02,\n",
       "                      -8.9208e-03,  6.6064e-03,  1.5754e-02,  1.5022e-02, -4.6663e-02,\n",
       "                      -4.6603e-02, -2.4326e-02, -3.4450e-04,  2.6657e-03, -1.4686e-02,\n",
       "                       4.3858e-02, -2.4205e-02,  2.7140e-02,  1.4228e-02, -3.2452e-02,\n",
       "                      -1.3697e-02, -2.2663e-02,  2.5105e-02, -3.5496e-02,  2.9163e-02,\n",
       "                      -2.7149e-02, -2.3556e-03, -4.1832e-03, -3.6136e-02,  1.0981e-02,\n",
       "                       9.4871e-03, -2.6573e-02, -2.9927e-02, -2.6906e-02, -3.0548e-02,\n",
       "                      -3.7895e-02,  1.5370e-02, -8.1441e-03,  2.2395e-02,  1.4819e-02,\n",
       "                       3.1395e-02, -1.4215e-02,  2.7523e-02,  3.7768e-03,  1.0399e-02,\n",
       "                       3.0434e-02,  8.8486e-03, -2.1522e-03,  3.6584e-02,  2.7457e-02,\n",
       "                      -1.7086e-02, -2.5439e-02,  6.7501e-03,  4.3169e-02, -2.6291e-02,\n",
       "                       3.0718e-02,  2.1833e-02,  1.4552e-04,  5.2537e-03, -5.3719e-04,\n",
       "                       2.1874e-02, -4.2464e-02,  8.6009e-03, -8.6438e-03, -1.8526e-02,\n",
       "                       3.4555e-03,  2.0619e-02,  3.4175e-02, -1.8055e-02,  1.7505e-02,\n",
       "                      -1.6789e-02, -4.7563e-02,  2.8319e-02,  1.0188e-03,  3.5437e-02,\n",
       "                       4.2929e-02,  4.0286e-02, -2.8194e-02, -1.8433e-02, -3.7007e-02,\n",
       "                       4.2993e-02,  2.0111e-02,  2.7696e-02, -2.1308e-02,  1.4699e-02,\n",
       "                      -4.7830e-03,  3.7592e-02, -8.2789e-03, -9.5796e-03,  8.7577e-04,\n",
       "                       1.2207e-03,  1.4414e-02, -3.1322e-02,  4.1420e-02,  3.1258e-02,\n",
       "                      -1.8137e-02, -3.8409e-02, -1.3876e-02, -1.2281e-02, -3.0642e-02,\n",
       "                      -2.0274e-02, -3.6475e-02,  1.7046e-02, -1.1224e-02, -3.1493e-02,\n",
       "                       8.6223e-03,  1.0229e-02, -7.6857e-03, -1.9868e-02, -2.4333e-02,\n",
       "                      -5.3831e-03,  3.2459e-02, -6.5627e-03, -9.1525e-03,  5.2212e-03,\n",
       "                       1.2819e-02, -2.0642e-02,  3.1342e-02, -1.6638e-02,  1.0405e-02,\n",
       "                       1.4946e-02,  7.0466e-03,  3.2145e-05, -1.7568e-02,  3.6595e-03,\n",
       "                      -1.5209e-02,  3.4974e-02, -2.7316e-03,  2.7117e-02,  2.7022e-02,\n",
       "                      -2.2722e-02, -3.7689e-03, -2.2176e-02, -4.2188e-02,  1.6847e-02,\n",
       "                      -1.9587e-02,  3.0429e-02,  4.1796e-04,  1.1914e-02,  1.8961e-02,\n",
       "                      -3.2941e-02, -4.5069e-02,  2.3083e-02,  2.6893e-02, -8.2973e-03,\n",
       "                      -7.6415e-03,  2.1829e-02,  4.4657e-02, -2.7553e-02, -2.2041e-02,\n",
       "                      -1.3414e-02,  1.0573e-03, -3.0316e-02, -3.8739e-02,  3.0994e-02,\n",
       "                      -3.4131e-02, -2.4561e-02,  1.6431e-02,  2.7021e-02, -1.0624e-02,\n",
       "                      -7.5937e-03,  1.9671e-02, -1.9197e-02, -3.9485e-02, -2.5373e-02,\n",
       "                      -1.8859e-02,  2.6788e-02, -6.0421e-03, -3.3586e-02, -2.1051e-02,\n",
       "                       3.4826e-02, -4.2316e-03, -2.8390e-02, -2.7765e-02, -4.2327e-02,\n",
       "                       4.7310e-02, -3.4859e-02, -4.0004e-02, -5.1283e-02,  4.3495e-02,\n",
       "                      -2.6570e-02, -4.3894e-02,  1.6667e-02,  2.3297e-02, -4.7864e-02,\n",
       "                      -4.7651e-02,  3.6106e-02,  1.8696e-02, -2.0166e-02,  2.1199e-02,\n",
       "                       2.0482e-02, -5.7596e-03,  7.3298e-04,  7.1409e-03, -4.0092e-02,\n",
       "                      -2.1505e-03,  3.2605e-02, -1.9306e-03,  3.1231e-03, -1.7367e-02,\n",
       "                      -7.6138e-03, -1.1527e-02,  1.4033e-02,  9.7737e-03, -1.5440e-02,\n",
       "                       3.9355e-02, -7.3547e-04, -1.5583e-02,  8.0731e-03, -4.9224e-03,\n",
       "                      -3.9677e-02,  1.1857e-02,  1.6303e-02,  1.3397e-02, -1.3504e-02,\n",
       "                       2.5361e-02, -4.1695e-02, -4.5609e-03, -4.4756e-02,  3.2969e-02,\n",
       "                       1.8433e-02, -3.2073e-02, -7.6042e-03,  1.9022e-02,  2.4168e-02,\n",
       "                      -9.4723e-03, -3.6824e-02,  1.9084e-02, -3.0131e-02,  3.0985e-02,\n",
       "                      -9.5205e-04, -9.1330e-03, -1.6189e-02,  1.2912e-02,  4.6255e-02,\n",
       "                       4.6189e-02,  2.3943e-02, -3.3250e-02,  4.8306e-02, -4.0545e-03,\n",
       "                       2.7672e-02, -3.3648e-03,  2.5626e-02, -1.6065e-02, -4.4500e-02,\n",
       "                      -5.1669e-03, -3.6556e-02,  1.9533e-02, -2.8096e-02,  3.4431e-02,\n",
       "                      -1.1633e-02,  9.8687e-04,  1.1048e-02, -4.4527e-02,  3.4845e-02,\n",
       "                      -3.8269e-02,  3.3348e-02,  3.0286e-02,  2.3840e-02, -2.4350e-02,\n",
       "                      -4.4408e-02,  1.9079e-02, -1.6055e-02, -2.1935e-02,  1.3092e-02,\n",
       "                       2.5809e-02,  1.5445e-02, -2.8903e-02,  3.2510e-02,  3.0378e-02,\n",
       "                       2.9938e-03, -2.1479e-02, -8.4446e-03, -2.9999e-02, -9.3731e-03,\n",
       "                       1.1960e-02,  2.8897e-02, -1.4685e-02,  2.0904e-02, -2.7529e-02,\n",
       "                       9.0971e-03, -2.4479e-02,  3.6691e-02, -2.0810e-02, -2.8542e-02,\n",
       "                       4.0315e-02, -3.0299e-02, -1.8905e-03, -1.5569e-02,  3.9948e-03,\n",
       "                      -1.9952e-02, -2.9483e-02,  4.3442e-02, -3.0671e-03, -1.4375e-03,\n",
       "                       3.3795e-02, -2.5213e-03, -2.4618e-02,  3.6130e-02, -2.2313e-02,\n",
       "                      -3.3276e-02, -2.8877e-02,  3.6566e-02,  2.4004e-02,  1.2181e-02,\n",
       "                      -3.1644e-02, -1.8377e-02, -2.6312e-02, -2.1631e-02,  2.6292e-02,\n",
       "                       2.0445e-02,  2.5778e-02, -4.1728e-02,  4.4758e-02,  1.1855e-02,\n",
       "                      -2.9969e-02, -3.1817e-02,  3.2525e-02,  4.1542e-04, -8.2376e-03,\n",
       "                      -2.5703e-02, -3.4353e-02,  2.6536e-02,  1.3827e-02,  3.3892e-02,\n",
       "                       1.2681e-02,  5.7277e-03, -2.0766e-02, -3.7713e-02, -4.0623e-03,\n",
       "                      -1.6662e-03,  4.5240e-04,  1.1737e-02,  6.5449e-03, -4.4895e-02,\n",
       "                      -1.8592e-02,  1.2471e-02,  1.4588e-02, -1.3392e-02, -1.7634e-02,\n",
       "                       1.9911e-02, -2.8868e-02, -4.5867e-02, -9.3506e-03, -1.2228e-02,\n",
       "                       3.0086e-02, -3.7574e-02,  4.6548e-03,  2.6595e-02, -2.3665e-03,\n",
       "                       1.2959e-02,  8.9384e-03, -4.6086e-02, -3.4375e-03, -1.4147e-02,\n",
       "                       6.1730e-04,  2.0148e-02, -3.7478e-02, -1.3236e-02, -1.1917e-02,\n",
       "                      -2.9676e-02, -1.9272e-02,  1.5376e-02, -4.9197e-02, -1.4736e-02,\n",
       "                       2.6244e-03,  5.3653e-03, -3.3068e-03,  1.7370e-02,  2.1647e-02,\n",
       "                       2.6376e-02, -9.0437e-06,  2.9081e-02,  1.8833e-02, -3.4147e-02,\n",
       "                      -1.4851e-02,  2.0437e-02,  1.3704e-02,  1.8384e-02,  9.5048e-03,\n",
       "                       1.9618e-02, -3.6189e-02, -1.5523e-02, -2.1929e-02, -2.9026e-02,\n",
       "                      -2.0473e-02, -4.1573e-02,  3.6286e-02,  1.3508e-02, -2.4008e-02,\n",
       "                      -1.1643e-02, -1.3682e-02, -2.3812e-02, -2.0107e-02, -2.2948e-02,\n",
       "                       2.0973e-02, -2.8401e-02,  3.7573e-02, -6.3462e-03,  2.3544e-02,\n",
       "                      -4.5164e-04, -8.6058e-04, -1.9926e-02,  1.1407e-02, -4.0707e-02,\n",
       "                       9.0971e-03,  2.0217e-02, -1.0409e-02, -8.8552e-03,  2.0214e-02,\n",
       "                      -1.3719e-02, -2.3800e-02,  2.8936e-02,  5.4995e-03, -3.3882e-02,\n",
       "                       4.3501e-02, -3.5352e-02, -9.0201e-03, -2.7847e-02,  1.5985e-02,\n",
       "                      -3.8399e-02,  1.9586e-02,  1.3451e-02, -8.8243e-03,  7.3760e-03,\n",
       "                      -2.2033e-03, -3.2480e-02,  6.0979e-03, -2.4595e-02, -1.4790e-02,\n",
       "                       3.6586e-02, -3.4965e-02,  4.7905e-02,  8.5420e-03, -4.9892e-03,\n",
       "                       2.0774e-02, -1.9296e-02, -1.2587e-02, -2.5316e-02,  1.9017e-02,\n",
       "                      -2.8771e-02,  2.1994e-02,  3.6055e-02,  2.5923e-02,  4.5590e-02,\n",
       "                      -3.6006e-02, -2.6337e-02,  2.6682e-02, -1.5546e-03,  1.8353e-02,\n",
       "                       3.1749e-03,  2.8941e-02, -7.5411e-03,  2.0850e-02, -4.4444e-02,\n",
       "                      -1.0923e-03, -1.1707e-02, -3.6601e-02, -1.4350e-02,  5.3683e-02,\n",
       "                      -9.1278e-03,  1.7444e-02,  1.1137e-02, -2.3549e-02,  1.6637e-03,\n",
       "                      -1.1388e-02,  2.7579e-02,  3.3152e-02, -7.7928e-03,  1.5931e-02,\n",
       "                      -3.6417e-02,  2.7453e-02,  2.5959e-02, -7.6511e-03,  3.8142e-02,\n",
       "                      -2.0489e-02, -3.4039e-02, -4.0039e-03,  3.6999e-02,  4.9561e-02,\n",
       "                      -2.4667e-03, -3.4064e-03, -3.1699e-02,  5.2222e-03, -1.4054e-02,\n",
       "                       2.7052e-02, -2.1456e-02, -1.8719e-02, -2.3268e-02, -3.6023e-03,\n",
       "                      -1.5668e-02, -2.8894e-02, -2.6651e-02,  3.8068e-02,  2.3833e-02,\n",
       "                      -3.8112e-02, -3.9571e-02, -3.6881e-03,  3.1428e-02,  3.2912e-02,\n",
       "                      -3.2270e-02, -6.0514e-04, -2.4869e-02,  1.0115e-02,  1.7992e-02,\n",
       "                      -6.8935e-03,  6.1855e-04], device='cuda:0')),\n",
       "             ('layers.1.conv.convs.<user___rates___book>.lin_r.weight',\n",
       "              tensor([[ 0.0114, -0.0330,  0.0412,  ..., -0.0043,  0.0200,  0.0070],\n",
       "                      [ 0.0366, -0.0057, -0.0376,  ...,  0.0492,  0.0121,  0.0372],\n",
       "                      [-0.0038,  0.0316,  0.0155,  ...,  0.0138,  0.0040, -0.0442],\n",
       "                      ...,\n",
       "                      [ 0.0304, -0.0479,  0.0182,  ..., -0.0071, -0.0052, -0.0032],\n",
       "                      [-0.0055, -0.0262,  0.0113,  ..., -0.0303,  0.0447, -0.0051],\n",
       "                      [-0.0111, -0.0182,  0.0208,  ..., -0.0447,  0.0045, -0.0367]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.1.conv.convs.<book___rev_rates___user>.lin_l.weight',\n",
       "              tensor([[-0.0079, -0.0469,  0.0347,  ...,  0.0340,  0.0028, -0.0023],\n",
       "                      [-0.0223,  0.0023,  0.0320,  ...,  0.0395, -0.0152,  0.0280],\n",
       "                      [ 0.0376,  0.0282,  0.0382,  ..., -0.0201, -0.0412, -0.0450],\n",
       "                      ...,\n",
       "                      [-0.0295, -0.0486, -0.0272,  ..., -0.0206, -0.0106, -0.0101],\n",
       "                      [-0.0323, -0.0123, -0.0207,  ...,  0.0140,  0.0003, -0.0406],\n",
       "                      [ 0.0041, -0.0247,  0.0016,  ..., -0.0063,  0.0445, -0.0189]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.1.conv.convs.<book___rev_rates___user>.lin_l.bias',\n",
       "              tensor([-1.1097e-03, -4.8203e-02,  2.2891e-02, -2.5854e-02, -5.0503e-03,\n",
       "                       1.7734e-02,  2.2911e-02, -1.0490e-02,  3.6572e-02,  1.8520e-02,\n",
       "                      -8.9208e-03,  6.6064e-03,  1.5754e-02,  1.5022e-02, -4.6663e-02,\n",
       "                      -4.6603e-02, -2.4326e-02, -3.4450e-04,  2.6657e-03, -1.4686e-02,\n",
       "                       4.3858e-02, -2.4205e-02,  2.7140e-02,  1.4228e-02, -3.2452e-02,\n",
       "                      -1.3697e-02, -2.2663e-02,  2.5105e-02, -3.5496e-02,  2.9163e-02,\n",
       "                      -2.7149e-02, -2.3556e-03, -4.1832e-03, -3.6136e-02,  1.0981e-02,\n",
       "                       9.4871e-03, -2.6573e-02, -2.9927e-02, -2.6906e-02, -3.0548e-02,\n",
       "                      -3.7895e-02,  1.5370e-02, -8.1441e-03,  2.2395e-02,  1.4819e-02,\n",
       "                       3.1395e-02, -1.4215e-02,  2.7523e-02,  3.7768e-03,  1.0399e-02,\n",
       "                       3.0434e-02,  8.8486e-03, -2.1522e-03,  3.6584e-02,  2.7457e-02,\n",
       "                      -1.7086e-02, -2.5439e-02,  6.7501e-03,  4.3169e-02, -2.6291e-02,\n",
       "                       3.0718e-02,  2.1833e-02,  1.4552e-04,  5.2537e-03, -5.3719e-04,\n",
       "                       2.1874e-02, -4.2464e-02,  8.6009e-03, -8.6438e-03, -1.8526e-02,\n",
       "                       3.4555e-03,  2.0619e-02,  3.4175e-02, -1.8055e-02,  1.7505e-02,\n",
       "                      -1.6789e-02, -4.7563e-02,  2.8319e-02,  1.0188e-03,  3.5437e-02,\n",
       "                       4.2929e-02,  4.0286e-02, -2.8194e-02, -1.8433e-02, -3.7007e-02,\n",
       "                       4.2993e-02,  2.0111e-02,  2.7696e-02, -2.1308e-02,  1.4699e-02,\n",
       "                      -4.7830e-03,  3.7592e-02, -8.2789e-03, -9.5796e-03,  8.7577e-04,\n",
       "                       1.2207e-03,  1.4414e-02, -3.1322e-02,  4.1420e-02,  3.1258e-02,\n",
       "                      -1.8137e-02, -3.8409e-02, -1.3876e-02, -1.2281e-02, -3.0642e-02,\n",
       "                      -2.0274e-02, -3.6475e-02,  1.7046e-02, -1.1224e-02, -3.1493e-02,\n",
       "                       8.6223e-03,  1.0229e-02, -7.6857e-03, -1.9868e-02, -2.4333e-02,\n",
       "                      -5.3831e-03,  3.2459e-02, -6.5627e-03, -9.1525e-03,  5.2212e-03,\n",
       "                       1.2819e-02, -2.0642e-02,  3.1342e-02, -1.6638e-02,  1.0405e-02,\n",
       "                       1.4946e-02,  7.0466e-03,  3.2145e-05, -1.7568e-02,  3.6595e-03,\n",
       "                      -1.5209e-02,  3.4974e-02, -2.7316e-03,  2.7117e-02,  2.7022e-02,\n",
       "                      -2.2722e-02, -3.7689e-03, -2.2176e-02, -4.2188e-02,  1.6847e-02,\n",
       "                      -1.9587e-02,  3.0429e-02,  4.1796e-04,  1.1914e-02,  1.8961e-02,\n",
       "                      -3.2941e-02, -4.5069e-02,  2.3083e-02,  2.6893e-02, -8.2973e-03,\n",
       "                      -7.6415e-03,  2.1829e-02,  4.4657e-02, -2.7553e-02, -2.2041e-02,\n",
       "                      -1.3414e-02,  1.0573e-03, -3.0316e-02, -3.8739e-02,  3.0994e-02,\n",
       "                      -3.4131e-02, -2.4561e-02,  1.6431e-02,  2.7021e-02, -1.0624e-02,\n",
       "                      -7.5937e-03,  1.9671e-02, -1.9197e-02, -3.9485e-02, -2.5373e-02,\n",
       "                      -1.8859e-02,  2.6788e-02, -6.0421e-03, -3.3586e-02, -2.1051e-02,\n",
       "                       3.4826e-02, -4.2316e-03, -2.8390e-02, -2.7765e-02, -4.2327e-02,\n",
       "                       4.7310e-02, -3.4859e-02, -4.0004e-02, -5.1283e-02,  4.3495e-02,\n",
       "                      -2.6570e-02, -4.3894e-02,  1.6667e-02,  2.3297e-02, -4.7864e-02,\n",
       "                      -4.7651e-02,  3.6106e-02,  1.8696e-02, -2.0166e-02,  2.1199e-02,\n",
       "                       2.0482e-02, -5.7596e-03,  7.3298e-04,  7.1409e-03, -4.0092e-02,\n",
       "                      -2.1505e-03,  3.2605e-02, -1.9306e-03,  3.1231e-03, -1.7367e-02,\n",
       "                      -7.6138e-03, -1.1527e-02,  1.4033e-02,  9.7737e-03, -1.5440e-02,\n",
       "                       3.9355e-02, -7.3547e-04, -1.5583e-02,  8.0731e-03, -4.9224e-03,\n",
       "                      -3.9677e-02,  1.1857e-02,  1.6303e-02,  1.3397e-02, -1.3504e-02,\n",
       "                       2.5361e-02, -4.1695e-02, -4.5609e-03, -4.4756e-02,  3.2969e-02,\n",
       "                       1.8433e-02, -3.2073e-02, -7.6042e-03,  1.9022e-02,  2.4168e-02,\n",
       "                      -9.4723e-03, -3.6824e-02,  1.9084e-02, -3.0131e-02,  3.0985e-02,\n",
       "                      -9.5205e-04, -9.1330e-03, -1.6189e-02,  1.2912e-02,  4.6255e-02,\n",
       "                       4.6189e-02,  2.3943e-02, -3.3250e-02,  4.8306e-02, -4.0545e-03,\n",
       "                       2.7672e-02, -3.3648e-03,  2.5626e-02, -1.6065e-02, -4.4500e-02,\n",
       "                      -5.1669e-03, -3.6556e-02,  1.9533e-02, -2.8096e-02,  3.4431e-02,\n",
       "                      -1.1633e-02,  9.8687e-04,  1.1048e-02, -4.4527e-02,  3.4845e-02,\n",
       "                      -3.8269e-02,  3.3348e-02,  3.0286e-02,  2.3840e-02, -2.4350e-02,\n",
       "                      -4.4408e-02,  1.9079e-02, -1.6055e-02, -2.1935e-02,  1.3092e-02,\n",
       "                       2.5809e-02,  1.5445e-02, -2.8903e-02,  3.2510e-02,  3.0378e-02,\n",
       "                       2.9938e-03, -2.1479e-02, -8.4446e-03, -2.9999e-02, -9.3731e-03,\n",
       "                       1.1960e-02,  2.8897e-02, -1.4685e-02,  2.0904e-02, -2.7529e-02,\n",
       "                       9.0971e-03, -2.4479e-02,  3.6691e-02, -2.0810e-02, -2.8542e-02,\n",
       "                       4.0315e-02, -3.0299e-02, -1.8905e-03, -1.5569e-02,  3.9948e-03,\n",
       "                      -1.9952e-02, -2.9483e-02,  4.3442e-02, -3.0671e-03, -1.4375e-03,\n",
       "                       3.3795e-02, -2.5213e-03, -2.4618e-02,  3.6130e-02, -2.2313e-02,\n",
       "                      -3.3276e-02, -2.8877e-02,  3.6566e-02,  2.4004e-02,  1.2181e-02,\n",
       "                      -3.1644e-02, -1.8377e-02, -2.6312e-02, -2.1631e-02,  2.6292e-02,\n",
       "                       2.0445e-02,  2.5778e-02, -4.1728e-02,  4.4758e-02,  1.1855e-02,\n",
       "                      -2.9969e-02, -3.1817e-02,  3.2525e-02,  4.1542e-04, -8.2376e-03,\n",
       "                      -2.5703e-02, -3.4353e-02,  2.6536e-02,  1.3827e-02,  3.3892e-02,\n",
       "                       1.2681e-02,  5.7277e-03, -2.0766e-02, -3.7713e-02, -4.0623e-03,\n",
       "                      -1.6662e-03,  4.5240e-04,  1.1737e-02,  6.5449e-03, -4.4895e-02,\n",
       "                      -1.8592e-02,  1.2471e-02,  1.4588e-02, -1.3392e-02, -1.7634e-02,\n",
       "                       1.9911e-02, -2.8868e-02, -4.5867e-02, -9.3506e-03, -1.2228e-02,\n",
       "                       3.0086e-02, -3.7574e-02,  4.6548e-03,  2.6595e-02, -2.3665e-03,\n",
       "                       1.2959e-02,  8.9384e-03, -4.6086e-02, -3.4375e-03, -1.4147e-02,\n",
       "                       6.1730e-04,  2.0148e-02, -3.7478e-02, -1.3236e-02, -1.1917e-02,\n",
       "                      -2.9676e-02, -1.9272e-02,  1.5376e-02, -4.9197e-02, -1.4736e-02,\n",
       "                       2.6244e-03,  5.3653e-03, -3.3068e-03,  1.7370e-02,  2.1647e-02,\n",
       "                       2.6376e-02, -9.0437e-06,  2.9081e-02,  1.8833e-02, -3.4147e-02,\n",
       "                      -1.4851e-02,  2.0437e-02,  1.3704e-02,  1.8384e-02,  9.5048e-03,\n",
       "                       1.9618e-02, -3.6189e-02, -1.5523e-02, -2.1929e-02, -2.9026e-02,\n",
       "                      -2.0473e-02, -4.1573e-02,  3.6286e-02,  1.3508e-02, -2.4008e-02,\n",
       "                      -1.1643e-02, -1.3682e-02, -2.3812e-02, -2.0107e-02, -2.2948e-02,\n",
       "                       2.0973e-02, -2.8401e-02,  3.7573e-02, -6.3462e-03,  2.3544e-02,\n",
       "                      -4.5164e-04, -8.6058e-04, -1.9926e-02,  1.1407e-02, -4.0707e-02,\n",
       "                       9.0971e-03,  2.0217e-02, -1.0409e-02, -8.8552e-03,  2.0214e-02,\n",
       "                      -1.3719e-02, -2.3800e-02,  2.8936e-02,  5.4995e-03, -3.3882e-02,\n",
       "                       4.3501e-02, -3.5352e-02, -9.0201e-03, -2.7847e-02,  1.5985e-02,\n",
       "                      -3.8399e-02,  1.9586e-02,  1.3451e-02, -8.8243e-03,  7.3760e-03,\n",
       "                      -2.2033e-03, -3.2480e-02,  6.0979e-03, -2.4595e-02, -1.4790e-02,\n",
       "                       3.6586e-02, -3.4965e-02,  4.7905e-02,  8.5420e-03, -4.9892e-03,\n",
       "                       2.0774e-02, -1.9296e-02, -1.2587e-02, -2.5316e-02,  1.9017e-02,\n",
       "                      -2.8771e-02,  2.1994e-02,  3.6055e-02,  2.5923e-02,  4.5590e-02,\n",
       "                      -3.6006e-02, -2.6337e-02,  2.6682e-02, -1.5546e-03,  1.8353e-02,\n",
       "                       3.1749e-03,  2.8941e-02, -7.5411e-03,  2.0850e-02, -4.4444e-02,\n",
       "                      -1.0923e-03, -1.1707e-02, -3.6601e-02, -1.4350e-02,  5.3683e-02,\n",
       "                      -9.1278e-03,  1.7444e-02,  1.1137e-02, -2.3549e-02,  1.6637e-03,\n",
       "                      -1.1388e-02,  2.7579e-02,  3.3152e-02, -7.7928e-03,  1.5931e-02,\n",
       "                      -3.6417e-02,  2.7453e-02,  2.5959e-02, -7.6511e-03,  3.8142e-02,\n",
       "                      -2.0489e-02, -3.4039e-02, -4.0039e-03,  3.6999e-02,  4.9561e-02,\n",
       "                      -2.4667e-03, -3.4064e-03, -3.1699e-02,  5.2222e-03, -1.4054e-02,\n",
       "                       2.7052e-02, -2.1456e-02, -1.8719e-02, -2.3268e-02, -3.6023e-03,\n",
       "                      -1.5668e-02, -2.8894e-02, -2.6651e-02,  3.8068e-02,  2.3833e-02,\n",
       "                      -3.8112e-02, -3.9571e-02, -3.6881e-03,  3.1428e-02,  3.2912e-02,\n",
       "                      -3.2270e-02, -6.0514e-04, -2.4869e-02,  1.0115e-02,  1.7992e-02,\n",
       "                      -6.8935e-03,  6.1855e-04], device='cuda:0')),\n",
       "             ('layers.1.conv.convs.<book___rev_rates___user>.lin_r.weight',\n",
       "              tensor([[ 0.0114, -0.0330,  0.0412,  ..., -0.0043,  0.0200,  0.0070],\n",
       "                      [ 0.0366, -0.0057, -0.0376,  ...,  0.0492,  0.0121,  0.0372],\n",
       "                      [-0.0038,  0.0316,  0.0155,  ...,  0.0138,  0.0040, -0.0442],\n",
       "                      ...,\n",
       "                      [ 0.0304, -0.0479,  0.0182,  ..., -0.0071, -0.0052, -0.0032],\n",
       "                      [-0.0055, -0.0262,  0.0113,  ..., -0.0303,  0.0447, -0.0051],\n",
       "                      [-0.0111, -0.0182,  0.0208,  ..., -0.0447,  0.0045, -0.0367]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.2.conv.convs.<user___rates___book>.lin_l.weight',\n",
       "              tensor([[ 4.4463e-02,  2.0663e-02, -1.7083e-02,  ..., -4.7671e-02,\n",
       "                       -1.3671e-02, -3.2980e-02],\n",
       "                      [ 3.6943e-02, -3.9190e-02,  4.5459e-02,  ...,  1.6256e-02,\n",
       "                        5.1776e-02,  6.5017e-02],\n",
       "                      [ 4.3130e-02,  2.2332e-02,  3.1428e-02,  ...,  3.8792e-02,\n",
       "                        2.7937e-02, -1.9530e-02],\n",
       "                      ...,\n",
       "                      [-3.9192e-02,  2.6926e-02, -1.6911e-02,  ...,  3.3648e-02,\n",
       "                       -5.5542e-02,  1.5776e-02],\n",
       "                      [ 2.6587e-02,  4.3449e-03, -2.5489e-02,  ..., -2.6105e-02,\n",
       "                       -5.1493e-02, -2.4262e-02],\n",
       "                      [-3.9577e-02,  1.7871e-02, -9.8728e-03,  ..., -3.2547e-03,\n",
       "                        5.3212e-05, -9.0520e-03]], device='cuda:0')),\n",
       "             ('layers.2.conv.convs.<user___rates___book>.lin_l.bias',\n",
       "              tensor([-0.0170,  0.0249,  0.0018, -0.0241, -0.0348, -0.0188,  0.0398, -0.0131,\n",
       "                      -0.0200,  0.0048,  0.0040,  0.0461,  0.0301, -0.0315, -0.0087, -0.0139,\n",
       "                       0.0114,  0.0071,  0.0021,  0.0368,  0.0173, -0.0138,  0.0020,  0.0481,\n",
       "                      -0.0282, -0.0006,  0.0412,  0.0459,  0.0095,  0.0318, -0.0149, -0.0038,\n",
       "                      -0.0362, -0.0144,  0.0538,  0.0002,  0.0266, -0.0381,  0.0273,  0.0359,\n",
       "                       0.0341,  0.0117, -0.0413, -0.0113, -0.0407,  0.0341, -0.0421, -0.0199,\n",
       "                      -0.0164, -0.0395,  0.0275,  0.0092,  0.0114,  0.0242, -0.0390,  0.0503,\n",
       "                      -0.0129,  0.0252,  0.0091,  0.0475, -0.0143,  0.0066, -0.0253, -0.0156,\n",
       "                      -0.0334,  0.0047,  0.0278,  0.0303, -0.0190,  0.0024, -0.0274,  0.0392,\n",
       "                       0.0133,  0.0309,  0.0116,  0.0179, -0.0009, -0.0204,  0.0358, -0.0035,\n",
       "                      -0.0017,  0.0188,  0.0044, -0.0409,  0.0167, -0.0005,  0.0283, -0.0071,\n",
       "                       0.0320, -0.0332,  0.0287, -0.0062,  0.0250,  0.0422, -0.0136, -0.0051,\n",
       "                       0.0178,  0.0422,  0.0473, -0.0263,  0.0265, -0.0167, -0.0043,  0.0382,\n",
       "                      -0.0404,  0.0270,  0.0240, -0.0331, -0.0361,  0.0196, -0.0165, -0.0100,\n",
       "                       0.0318,  0.0246, -0.0111, -0.0226,  0.0399, -0.0005,  0.0398, -0.0085,\n",
       "                       0.0243, -0.0170,  0.0229,  0.0156,  0.0105, -0.0029, -0.0385, -0.0448,\n",
       "                      -0.0355,  0.0262,  0.0450, -0.0437, -0.0224, -0.0079,  0.0019,  0.0106,\n",
       "                      -0.0426, -0.0055,  0.0193,  0.0172,  0.0307,  0.0480,  0.0152,  0.0262,\n",
       "                       0.0302,  0.0365, -0.0017,  0.0037,  0.0469, -0.0058,  0.0399, -0.0059,\n",
       "                      -0.0118,  0.0040,  0.0429,  0.0426,  0.0038, -0.0081,  0.0374,  0.0237,\n",
       "                       0.0232,  0.0365,  0.0011,  0.0216, -0.0224, -0.0197, -0.0126,  0.0486,\n",
       "                      -0.0142, -0.0477, -0.0332,  0.0517, -0.0113,  0.0256,  0.0013, -0.0009,\n",
       "                      -0.0508,  0.0383,  0.0277,  0.0326, -0.0415, -0.0234,  0.0476,  0.0582,\n",
       "                       0.0521,  0.0291,  0.0416,  0.0494, -0.0007,  0.0337,  0.0286,  0.0314,\n",
       "                       0.0176,  0.0104, -0.0004,  0.0107,  0.0261,  0.0424,  0.0340, -0.0228,\n",
       "                      -0.0009,  0.0448,  0.0287, -0.0228,  0.0262,  0.0041,  0.0130, -0.0278,\n",
       "                      -0.0038, -0.0119, -0.0095, -0.0351, -0.0068,  0.0332, -0.0388,  0.0223,\n",
       "                       0.0299,  0.0359,  0.0064,  0.0469,  0.0212, -0.0150, -0.0064, -0.0276,\n",
       "                      -0.0234, -0.0422,  0.0153, -0.0122, -0.0077, -0.0433, -0.0225,  0.0147,\n",
       "                      -0.0133, -0.0035, -0.0045, -0.0333,  0.0119,  0.0128, -0.0004,  0.0119,\n",
       "                      -0.0264, -0.0283, -0.0373,  0.0047,  0.0237,  0.0131, -0.0025,  0.0351,\n",
       "                      -0.0129, -0.0035, -0.0270,  0.0332,  0.0451, -0.0090, -0.0212,  0.0184,\n",
       "                      -0.0189, -0.0371,  0.0305, -0.0040,  0.0280, -0.0078, -0.0114, -0.0109,\n",
       "                       0.0241,  0.0239,  0.0013, -0.0217, -0.0075,  0.0287,  0.0300,  0.0264,\n",
       "                       0.0018, -0.0118, -0.0142, -0.0384,  0.0516,  0.0169,  0.0489, -0.0069,\n",
       "                       0.0246,  0.0643,  0.0419,  0.0074, -0.0046,  0.0383,  0.0060, -0.0299,\n",
       "                       0.0445, -0.0101, -0.0185,  0.0290,  0.0150,  0.0381,  0.0334, -0.0010,\n",
       "                      -0.0056,  0.0274, -0.0170,  0.0387,  0.0428,  0.0091, -0.0098, -0.0399,\n",
       "                      -0.0103,  0.0376,  0.0324,  0.0080, -0.0006, -0.0065,  0.0357, -0.0447,\n",
       "                       0.0221, -0.0058,  0.0215,  0.0281,  0.0045, -0.0182, -0.0216, -0.0208,\n",
       "                      -0.0273,  0.0130,  0.0174, -0.0171, -0.0220, -0.0247,  0.0405,  0.0135,\n",
       "                       0.0034, -0.0309,  0.0157,  0.0017,  0.0113, -0.0245, -0.0096, -0.0194,\n",
       "                       0.0103, -0.0175, -0.0414, -0.0106,  0.0200, -0.0433, -0.0221,  0.0408,\n",
       "                       0.0160, -0.0246,  0.0507, -0.0030,  0.0348, -0.0011,  0.0021, -0.0121,\n",
       "                       0.0233, -0.0399, -0.0187,  0.0069,  0.0071, -0.0299,  0.0130,  0.0148,\n",
       "                      -0.0278,  0.0143, -0.0016, -0.0257,  0.0143,  0.0255,  0.0400,  0.0416,\n",
       "                       0.0230,  0.0193,  0.0018,  0.0365,  0.0429, -0.0359, -0.0057,  0.0441,\n",
       "                      -0.0046, -0.0141,  0.0175, -0.0277, -0.0292, -0.0027, -0.0488,  0.0032,\n",
       "                       0.0155, -0.0104,  0.0011,  0.0174, -0.0350, -0.0345,  0.0367, -0.0316,\n",
       "                      -0.0160, -0.0164,  0.0116,  0.0261, -0.0045,  0.0327, -0.0236,  0.0180,\n",
       "                       0.0267,  0.0165, -0.0080,  0.0297, -0.0289, -0.0303,  0.0472, -0.0114,\n",
       "                      -0.0080, -0.0355, -0.0100,  0.0233,  0.0341,  0.0299,  0.0215, -0.0258,\n",
       "                      -0.0102,  0.0248, -0.0349,  0.0289, -0.0202,  0.0163,  0.0037,  0.0023,\n",
       "                       0.0041, -0.0036, -0.0197, -0.0419,  0.0042,  0.0117,  0.0376, -0.0021,\n",
       "                       0.0424, -0.0220,  0.0346,  0.0398,  0.0238,  0.0284, -0.0336, -0.0032,\n",
       "                      -0.0433, -0.0306,  0.0032, -0.0043,  0.0043, -0.0266, -0.0162,  0.0217,\n",
       "                      -0.0029,  0.0109, -0.0319, -0.0197,  0.0256, -0.0039,  0.0130, -0.0352,\n",
       "                      -0.0359, -0.0009,  0.0490, -0.0070,  0.0156,  0.0231,  0.0166, -0.0237,\n",
       "                       0.0015, -0.0365, -0.0091,  0.0210,  0.0492,  0.0128, -0.0158,  0.0378,\n",
       "                      -0.0365, -0.0390, -0.0321,  0.0139,  0.0008, -0.0070, -0.0171,  0.0488,\n",
       "                       0.0056,  0.0013,  0.0448, -0.0021,  0.0248,  0.0128,  0.0090, -0.0207,\n",
       "                      -0.0461, -0.0473, -0.0073,  0.0359, -0.0204, -0.0352,  0.0128,  0.0243,\n",
       "                      -0.0183,  0.0211,  0.0075, -0.0218, -0.0030, -0.0274,  0.0132,  0.0262,\n",
       "                       0.0310, -0.0100, -0.0414, -0.0031, -0.0195,  0.0377, -0.0289, -0.0060],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.2.conv.convs.<user___rates___book>.lin_r.weight',\n",
       "              tensor([[ 0.0362, -0.0024, -0.0483,  ..., -0.0065,  0.0094,  0.0098],\n",
       "                      [-0.0203,  0.0281, -0.0063,  ...,  0.0266,  0.0114,  0.0230],\n",
       "                      [-0.0088, -0.0127,  0.0200,  ...,  0.0332,  0.0046, -0.0384],\n",
       "                      ...,\n",
       "                      [-0.0298,  0.0293,  0.0366,  ..., -0.0403, -0.0492,  0.0192],\n",
       "                      [ 0.0281,  0.0323,  0.0067,  ..., -0.0356, -0.0233, -0.0154],\n",
       "                      [-0.0374, -0.0296,  0.0320,  ...,  0.0343,  0.0232,  0.0393]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.2.conv.convs.<book___rev_rates___user>.lin_l.weight',\n",
       "              tensor([[ 4.4463e-02,  2.0663e-02, -1.7083e-02,  ..., -4.7671e-02,\n",
       "                       -1.3671e-02, -3.2980e-02],\n",
       "                      [ 3.6943e-02, -3.9190e-02,  4.5459e-02,  ...,  1.6256e-02,\n",
       "                        5.1776e-02,  6.5017e-02],\n",
       "                      [ 4.3130e-02,  2.2332e-02,  3.1428e-02,  ...,  3.8792e-02,\n",
       "                        2.7937e-02, -1.9530e-02],\n",
       "                      ...,\n",
       "                      [-3.9192e-02,  2.6926e-02, -1.6911e-02,  ...,  3.3648e-02,\n",
       "                       -5.5542e-02,  1.5776e-02],\n",
       "                      [ 2.6587e-02,  4.3449e-03, -2.5489e-02,  ..., -2.6105e-02,\n",
       "                       -5.1493e-02, -2.4262e-02],\n",
       "                      [-3.9577e-02,  1.7871e-02, -9.8728e-03,  ..., -3.2547e-03,\n",
       "                        5.3212e-05, -9.0520e-03]], device='cuda:0')),\n",
       "             ('layers.2.conv.convs.<book___rev_rates___user>.lin_l.bias',\n",
       "              tensor([-0.0170,  0.0249,  0.0018, -0.0241, -0.0348, -0.0188,  0.0398, -0.0131,\n",
       "                      -0.0200,  0.0048,  0.0040,  0.0461,  0.0301, -0.0315, -0.0087, -0.0139,\n",
       "                       0.0114,  0.0071,  0.0021,  0.0368,  0.0173, -0.0138,  0.0020,  0.0481,\n",
       "                      -0.0282, -0.0006,  0.0412,  0.0459,  0.0095,  0.0318, -0.0149, -0.0038,\n",
       "                      -0.0362, -0.0144,  0.0538,  0.0002,  0.0266, -0.0381,  0.0273,  0.0359,\n",
       "                       0.0341,  0.0117, -0.0413, -0.0113, -0.0407,  0.0341, -0.0421, -0.0199,\n",
       "                      -0.0164, -0.0395,  0.0275,  0.0092,  0.0114,  0.0242, -0.0390,  0.0503,\n",
       "                      -0.0129,  0.0252,  0.0091,  0.0475, -0.0143,  0.0066, -0.0253, -0.0156,\n",
       "                      -0.0334,  0.0047,  0.0278,  0.0303, -0.0190,  0.0024, -0.0274,  0.0392,\n",
       "                       0.0133,  0.0309,  0.0116,  0.0179, -0.0009, -0.0204,  0.0358, -0.0035,\n",
       "                      -0.0017,  0.0188,  0.0044, -0.0409,  0.0167, -0.0005,  0.0283, -0.0071,\n",
       "                       0.0320, -0.0332,  0.0287, -0.0062,  0.0250,  0.0422, -0.0136, -0.0051,\n",
       "                       0.0178,  0.0422,  0.0473, -0.0263,  0.0265, -0.0167, -0.0043,  0.0382,\n",
       "                      -0.0404,  0.0270,  0.0240, -0.0331, -0.0361,  0.0196, -0.0165, -0.0100,\n",
       "                       0.0318,  0.0246, -0.0111, -0.0226,  0.0399, -0.0005,  0.0398, -0.0085,\n",
       "                       0.0243, -0.0170,  0.0229,  0.0156,  0.0105, -0.0029, -0.0385, -0.0448,\n",
       "                      -0.0355,  0.0262,  0.0450, -0.0437, -0.0224, -0.0079,  0.0019,  0.0106,\n",
       "                      -0.0426, -0.0055,  0.0193,  0.0172,  0.0307,  0.0480,  0.0152,  0.0262,\n",
       "                       0.0302,  0.0365, -0.0017,  0.0037,  0.0469, -0.0058,  0.0399, -0.0059,\n",
       "                      -0.0118,  0.0040,  0.0429,  0.0426,  0.0038, -0.0081,  0.0374,  0.0237,\n",
       "                       0.0232,  0.0365,  0.0011,  0.0216, -0.0224, -0.0197, -0.0126,  0.0486,\n",
       "                      -0.0142, -0.0477, -0.0332,  0.0517, -0.0113,  0.0256,  0.0013, -0.0009,\n",
       "                      -0.0508,  0.0383,  0.0277,  0.0326, -0.0415, -0.0234,  0.0476,  0.0582,\n",
       "                       0.0521,  0.0291,  0.0416,  0.0494, -0.0007,  0.0337,  0.0286,  0.0314,\n",
       "                       0.0176,  0.0104, -0.0004,  0.0107,  0.0261,  0.0424,  0.0340, -0.0228,\n",
       "                      -0.0009,  0.0448,  0.0287, -0.0228,  0.0262,  0.0041,  0.0130, -0.0278,\n",
       "                      -0.0038, -0.0119, -0.0095, -0.0351, -0.0068,  0.0332, -0.0388,  0.0223,\n",
       "                       0.0299,  0.0359,  0.0064,  0.0469,  0.0212, -0.0150, -0.0064, -0.0276,\n",
       "                      -0.0234, -0.0422,  0.0153, -0.0122, -0.0077, -0.0433, -0.0225,  0.0147,\n",
       "                      -0.0133, -0.0035, -0.0045, -0.0333,  0.0119,  0.0128, -0.0004,  0.0119,\n",
       "                      -0.0264, -0.0283, -0.0373,  0.0047,  0.0237,  0.0131, -0.0025,  0.0351,\n",
       "                      -0.0129, -0.0035, -0.0270,  0.0332,  0.0451, -0.0090, -0.0212,  0.0184,\n",
       "                      -0.0189, -0.0371,  0.0305, -0.0040,  0.0280, -0.0078, -0.0114, -0.0109,\n",
       "                       0.0241,  0.0239,  0.0013, -0.0217, -0.0075,  0.0287,  0.0300,  0.0264,\n",
       "                       0.0018, -0.0118, -0.0142, -0.0384,  0.0516,  0.0169,  0.0489, -0.0069,\n",
       "                       0.0246,  0.0643,  0.0419,  0.0074, -0.0046,  0.0383,  0.0060, -0.0299,\n",
       "                       0.0445, -0.0101, -0.0185,  0.0290,  0.0150,  0.0381,  0.0334, -0.0010,\n",
       "                      -0.0056,  0.0274, -0.0170,  0.0387,  0.0428,  0.0091, -0.0098, -0.0399,\n",
       "                      -0.0103,  0.0376,  0.0324,  0.0080, -0.0006, -0.0065,  0.0357, -0.0447,\n",
       "                       0.0221, -0.0058,  0.0215,  0.0281,  0.0045, -0.0182, -0.0216, -0.0208,\n",
       "                      -0.0273,  0.0130,  0.0174, -0.0171, -0.0220, -0.0247,  0.0405,  0.0135,\n",
       "                       0.0034, -0.0309,  0.0157,  0.0017,  0.0113, -0.0245, -0.0096, -0.0194,\n",
       "                       0.0103, -0.0175, -0.0414, -0.0106,  0.0200, -0.0433, -0.0221,  0.0408,\n",
       "                       0.0160, -0.0246,  0.0507, -0.0030,  0.0348, -0.0011,  0.0021, -0.0121,\n",
       "                       0.0233, -0.0399, -0.0187,  0.0069,  0.0071, -0.0299,  0.0130,  0.0148,\n",
       "                      -0.0278,  0.0143, -0.0016, -0.0257,  0.0143,  0.0255,  0.0400,  0.0416,\n",
       "                       0.0230,  0.0193,  0.0018,  0.0365,  0.0429, -0.0359, -0.0057,  0.0441,\n",
       "                      -0.0046, -0.0141,  0.0175, -0.0277, -0.0292, -0.0027, -0.0488,  0.0032,\n",
       "                       0.0155, -0.0104,  0.0011,  0.0174, -0.0350, -0.0345,  0.0367, -0.0316,\n",
       "                      -0.0160, -0.0164,  0.0116,  0.0261, -0.0045,  0.0327, -0.0236,  0.0180,\n",
       "                       0.0267,  0.0165, -0.0080,  0.0297, -0.0289, -0.0303,  0.0472, -0.0114,\n",
       "                      -0.0080, -0.0355, -0.0100,  0.0233,  0.0341,  0.0299,  0.0215, -0.0258,\n",
       "                      -0.0102,  0.0248, -0.0349,  0.0289, -0.0202,  0.0163,  0.0037,  0.0023,\n",
       "                       0.0041, -0.0036, -0.0197, -0.0419,  0.0042,  0.0117,  0.0376, -0.0021,\n",
       "                       0.0424, -0.0220,  0.0346,  0.0398,  0.0238,  0.0284, -0.0336, -0.0032,\n",
       "                      -0.0433, -0.0306,  0.0032, -0.0043,  0.0043, -0.0266, -0.0162,  0.0217,\n",
       "                      -0.0029,  0.0109, -0.0319, -0.0197,  0.0256, -0.0039,  0.0130, -0.0352,\n",
       "                      -0.0359, -0.0009,  0.0490, -0.0070,  0.0156,  0.0231,  0.0166, -0.0237,\n",
       "                       0.0015, -0.0365, -0.0091,  0.0210,  0.0492,  0.0128, -0.0158,  0.0378,\n",
       "                      -0.0365, -0.0390, -0.0321,  0.0139,  0.0008, -0.0070, -0.0171,  0.0488,\n",
       "                       0.0056,  0.0013,  0.0448, -0.0021,  0.0248,  0.0128,  0.0090, -0.0207,\n",
       "                      -0.0461, -0.0473, -0.0073,  0.0359, -0.0204, -0.0352,  0.0128,  0.0243,\n",
       "                      -0.0183,  0.0211,  0.0075, -0.0218, -0.0030, -0.0274,  0.0132,  0.0262,\n",
       "                       0.0310, -0.0100, -0.0414, -0.0031, -0.0195,  0.0377, -0.0289, -0.0060],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.2.conv.convs.<book___rev_rates___user>.lin_r.weight',\n",
       "              tensor([[ 0.0362, -0.0024, -0.0483,  ..., -0.0065,  0.0094,  0.0098],\n",
       "                      [-0.0203,  0.0281, -0.0063,  ...,  0.0266,  0.0114,  0.0230],\n",
       "                      [-0.0088, -0.0127,  0.0200,  ...,  0.0332,  0.0046, -0.0384],\n",
       "                      ...,\n",
       "                      [-0.0298,  0.0293,  0.0366,  ..., -0.0403, -0.0492,  0.0192],\n",
       "                      [ 0.0281,  0.0323,  0.0067,  ..., -0.0356, -0.0233, -0.0154],\n",
       "                      [-0.0374, -0.0296,  0.0320,  ...,  0.0343,  0.0232,  0.0393]],\n",
       "                     device='cuda:0')),\n",
       "             ('user_norm.weight',\n",
       "              tensor([0.9579, 1.0226, 0.9984, 1.0065, 0.9260, 1.0107, 0.9994, 0.9142, 0.9670,\n",
       "                      1.0068, 1.0082, 1.0027, 1.0000, 0.9226, 0.9652, 0.9983, 1.0208, 0.9688,\n",
       "                      0.9772, 1.0118, 1.0040, 0.9961, 0.9962, 1.0200, 0.9428, 0.9938, 0.9273,\n",
       "                      0.9447, 1.0100, 0.9681, 1.0107, 0.9990, 0.9300, 0.9613, 1.0103, 0.8753,\n",
       "                      1.0213, 0.9817, 1.0170, 0.9021, 1.0080, 0.9816, 1.0204, 0.9775, 1.0132,\n",
       "                      1.0315, 0.9162, 0.9708, 0.9526, 0.9771, 1.0082, 1.0000, 0.9309, 0.9985,\n",
       "                      1.0243, 1.0013, 1.0057, 0.9969, 0.9676, 1.0153, 1.0261, 1.0194, 1.0139,\n",
       "                      1.0346, 0.9980, 1.0041, 0.9745, 1.0182, 1.0001, 1.0079, 1.0140, 0.9379,\n",
       "                      0.9664, 1.0019, 1.0219, 0.9146, 1.0097, 1.0048, 0.9995, 0.9436, 0.9967,\n",
       "                      1.0200, 1.0203, 0.9653, 1.0187, 0.9196, 1.0163, 1.0241, 1.0538, 0.9264,\n",
       "                      1.0188, 0.9893, 0.9628, 1.0112, 1.0269, 0.9658, 0.9185, 1.0027, 1.0027,\n",
       "                      1.0236, 1.0159, 1.0034, 1.0292, 1.0053, 0.9516, 1.0462, 0.9787, 0.9739,\n",
       "                      0.9495, 1.0372, 0.9977, 0.9520, 1.0124, 1.0000, 0.9937, 0.9685, 1.0396,\n",
       "                      0.9563, 1.0104, 1.0180, 1.0036, 0.9749, 0.9464, 0.9098, 0.9287, 1.0326,\n",
       "                      1.0007, 0.9663, 0.9712, 1.0166, 1.0100, 0.9729, 0.9666, 1.0638, 0.9249,\n",
       "                      1.0411, 0.9954, 0.9764, 1.0029, 0.9677, 1.0002, 0.9238, 1.0132, 0.9977,\n",
       "                      0.9783, 1.0276, 1.0054, 0.9802, 1.0029, 0.9574, 1.0194, 1.0008, 0.9971,\n",
       "                      1.0101, 1.0157, 0.9701, 0.9751, 1.0151, 0.9703, 1.0044, 1.0412, 1.0109,\n",
       "                      0.9987, 0.9972, 1.0069, 1.0026, 0.9550, 1.0153, 0.9967, 0.9643, 0.9605,\n",
       "                      1.0138, 1.0005, 0.9997, 0.9979, 0.9975, 0.9625, 1.0311, 0.9434, 1.0177,\n",
       "                      1.0258, 1.0266, 0.9334, 1.0109, 1.0073, 1.0206, 1.0082, 1.0371, 0.9490,\n",
       "                      1.0040, 0.9943, 1.0165, 1.0117, 1.0303, 1.0000, 1.0207, 1.0252, 1.0180,\n",
       "                      1.0518, 1.0151, 0.9566, 1.0051, 1.0094, 1.0450, 0.9601, 0.9755, 1.0103,\n",
       "                      0.9013, 1.0145, 0.9111, 1.0112, 1.0102, 1.0002, 1.0279, 1.0058, 0.9976,\n",
       "                      1.0045, 0.9946, 1.0025, 1.0266, 1.0179, 0.9799, 0.9519, 1.0053, 0.9775,\n",
       "                      0.9736, 0.9974, 1.0035, 0.9550, 0.9584, 0.9366, 1.0353, 1.0283, 0.9678,\n",
       "                      1.0086, 1.0123, 1.0150, 1.0012, 1.0026, 1.0247, 1.0225, 1.0075, 0.9968,\n",
       "                      0.9996, 0.9974, 1.0309, 0.9366, 1.0326, 1.0509, 0.9957, 0.9761, 0.9241,\n",
       "                      1.0162, 0.9551, 1.0043, 1.0490, 0.9669, 1.0092, 0.9968, 1.0110, 0.9746,\n",
       "                      1.0326, 0.9998, 0.9993, 1.0155, 0.9546, 1.0475, 1.0323, 0.9965, 0.9680,\n",
       "                      0.9754, 1.0210, 0.9456, 0.9722, 0.9750, 0.9037, 0.9810, 1.0110, 1.0063,\n",
       "                      1.0094, 1.0034, 1.0091, 0.9979, 1.0225, 1.0092, 1.0404, 0.9549, 1.0041,\n",
       "                      0.9991, 0.9724, 0.9168, 0.9694, 0.9989, 1.0250, 0.9599, 1.0096, 0.9934,\n",
       "                      1.0443, 0.9302, 0.9902, 1.0022, 1.0299, 0.9812, 1.0214, 1.0633, 1.0037,\n",
       "                      1.0010, 0.9209, 1.0139, 1.0009, 1.0092, 0.9954, 0.9733, 1.0159, 1.0140,\n",
       "                      1.0257, 1.0182, 1.0049, 0.9770, 0.9257, 1.0234, 1.0039, 1.0048, 0.9953,\n",
       "                      1.0045, 1.0073, 1.0061, 1.0052, 0.9796, 0.9366, 1.0345, 0.9549, 1.0087,\n",
       "                      0.9844, 1.0470, 1.0138, 0.9669, 1.0175, 0.9067, 0.9754, 1.0407, 0.9452,\n",
       "                      1.0231, 1.0218, 0.9149, 0.9433, 1.0291, 1.0399, 0.9306, 1.0011, 1.0013,\n",
       "                      0.9622, 1.0035, 1.0682, 0.9633, 0.9909, 0.9942, 1.0252, 0.9672, 1.0173,\n",
       "                      1.0302, 1.0200, 0.9746, 0.9965, 0.9335, 1.0286, 1.0190, 0.9032, 1.0151,\n",
       "                      1.0136, 1.0195, 0.9477, 1.0126, 1.0145, 1.0603, 0.9999, 0.9999, 1.0081,\n",
       "                      0.9965, 0.9608, 1.0118, 1.0062, 0.9930, 1.0116, 1.0140, 1.0156, 1.0339,\n",
       "                      1.0192, 0.9342, 1.0059, 0.9639, 1.0100, 1.0054, 1.0169, 0.9872, 1.0302,\n",
       "                      0.9997, 0.9394, 1.0255, 1.0089, 1.0249, 0.9944, 0.9723, 0.9740, 1.0135,\n",
       "                      1.0006, 1.0247, 1.0050, 1.0075, 0.9673, 1.0057, 0.8965, 1.0401, 1.0276,\n",
       "                      0.9685, 1.0056, 1.0034, 0.9733, 1.0097, 0.9452, 0.9700, 0.9861, 0.9589,\n",
       "                      1.0243, 1.0086, 1.0006, 0.9952, 1.0389, 1.0169, 0.9609, 0.9979, 0.9587,\n",
       "                      0.9109, 1.0064, 0.9711, 0.9948, 0.9963, 1.0171, 1.0201, 0.9597, 0.9948,\n",
       "                      0.9448, 0.9979, 1.0157, 1.0133, 1.0242, 0.9625, 0.9642, 1.0305, 1.0007,\n",
       "                      1.0261, 0.9746, 0.9722, 1.0130, 0.9543, 0.9388, 0.9997, 0.9610, 0.9948,\n",
       "                      1.0055, 1.0203, 0.9277, 1.0042, 1.0115, 0.9797, 0.9180, 0.9426, 0.9733,\n",
       "                      0.9994, 0.9948, 0.9359, 1.0084, 1.0152, 1.0072, 0.9644, 0.9969, 0.9522,\n",
       "                      1.0074, 0.9935, 1.0441, 1.0093, 1.0189, 0.9499, 1.0028, 1.0136, 0.9751,\n",
       "                      0.9965, 0.9967, 1.0060, 1.0129, 1.0004, 0.9980, 0.9824, 0.9580, 1.0233,\n",
       "                      1.0183, 0.9269, 0.9720, 1.0389, 0.9859, 0.9496, 0.9995, 0.9702, 1.0121,\n",
       "                      1.0329, 1.0071, 1.0012, 1.0181, 1.0594, 1.0353, 0.9547, 1.0115],\n",
       "                     device='cuda:0')),\n",
       "             ('user_norm.bias',\n",
       "              tensor([-0.0325, -0.0318, -0.0123, -0.0432,  0.0985, -0.0038, -0.0062,  0.0999,\n",
       "                      -0.0219, -0.0112, -0.0158, -0.0280, -0.0424, -0.0491,  0.0699, -0.0561,\n",
       "                      -0.0287, -0.0260, -0.0204, -0.0284, -0.0695, -0.0009, -0.0515, -0.0707,\n",
       "                       0.0532, -0.0076, -0.0305, -0.0242, -0.0260, -0.0190, -0.0593, -0.0171,\n",
       "                       0.1003,  0.0710, -0.0532, -0.0625, -0.0308,  0.0087, -0.0648, -0.0504,\n",
       "                      -0.0326, -0.0241, -0.0597, -0.0340, -0.0716, -0.0426,  0.0942, -0.0309,\n",
       "                      -0.0302, -0.0264, -0.0293, -0.0692, -0.0322, -0.0114, -0.0718, -0.0277,\n",
       "                      -0.0344, -0.0104, -0.0183, -0.0556, -0.0944, -0.0824, -0.0541, -0.0295,\n",
       "                      -0.0198, -0.0535, -0.0081, -0.0249, -0.0100, -0.0073, -0.0360, -0.0381,\n",
       "                      -0.0322, -0.0366, -0.0615, -0.0723, -0.0183, -0.0234, -0.0312,  0.1004,\n",
       "                      -0.0665, -0.0495, -0.0565, -0.0325, -0.0969, -0.0268, -0.0570, -0.0527,\n",
       "                      -0.0862,  0.0454, -0.0596, -0.0276, -0.0242, -0.0461, -0.0763, -0.0253,\n",
       "                      -0.0497, -0.0124, -0.0215, -0.0686, -0.0785, -0.0033, -0.0197, -0.0216,\n",
       "                      -0.0208, -0.0552, -0.0107, -0.0075,  0.0627, -0.0352, -0.0154,  0.0710,\n",
       "                      -0.0224, -0.0107, -0.0108, -0.0094, -0.0511, -0.0205, -0.0519, -0.0212,\n",
       "                      -0.0288, -0.0153, -0.0223, -0.0127, -0.0380, -0.0599, -0.0269,  0.1146,\n",
       "                      -0.0208, -0.0605, -0.0274, -0.0340, -0.0378, -0.0874,  0.0826, -0.0485,\n",
       "                      -0.0184, -0.0244, -0.0254, -0.0346, -0.0733, -0.0468, -0.0149, -0.0250,\n",
       "                      -0.0379, -0.0249, -0.0015, -0.0267, -0.0338, -0.0060, -0.0310, -0.0218,\n",
       "                      -0.0166, -0.0171, -0.0614, -0.0402, -0.0335, -0.0125,  0.0341, -0.0702,\n",
       "                      -0.0701, -0.0354, -0.0241, -0.0214, -0.0351, -0.0700, -0.0311, -0.0239,\n",
       "                      -0.0126,  0.0158,  0.0052, -0.0619, -0.0585, -0.0407, -0.0050, -0.0597,\n",
       "                       0.0459, -0.0728, -0.0347, -0.0654, -0.0645, -0.0431, -0.0443, -0.0167,\n",
       "                      -0.0093, -0.0526, -0.0264, -0.0413,  0.0395, -0.0166, -0.0093, -0.0569,\n",
       "                      -0.0168, -0.0531, -0.0093, -0.0131, -0.0685, -0.0377, -0.0715, -0.0348,\n",
       "                      -0.0333, -0.0091, -0.0355, -0.0631, -0.0482, -0.0262, -0.0116, -0.0110,\n",
       "                      -0.0722, -0.0534, -0.0114, -0.0338, -0.0676, -0.0660, -0.0144, -0.0082,\n",
       "                      -0.0602, -0.0145, -0.0685, -0.0535, -0.0553, -0.0199, -0.0514, -0.0100,\n",
       "                      -0.0363, -0.0275, -0.0060, -0.0660, -0.0148,  0.0091,  0.0902, -0.0582,\n",
       "                      -0.0192, -0.0159, -0.0886, -0.0489, -0.0387, -0.0451, -0.0080, -0.0206,\n",
       "                      -0.0411, -0.0457, -0.0188, -0.0246, -0.0298, -0.0625,  0.0961, -0.0517,\n",
       "                      -0.0817, -0.0190,  0.0470, -0.0627, -0.0781, -0.0123, -0.0239, -0.0430,\n",
       "                      -0.0176, -0.0185, -0.0334, -0.0722, -0.0496, -0.0333, -0.0333, -0.0263,\n",
       "                      -0.0305, -0.0165, -0.0894, -0.0412, -0.0039, -0.0231, -0.0239, -0.0346,\n",
       "                       0.1079, -0.0191, -0.0267,  0.0795, -0.0345, -0.0109, -0.0463, -0.0224,\n",
       "                      -0.0207, -0.0184, -0.0279, -0.0198, -0.0160, -0.0870,  0.0386, -0.0035,\n",
       "                      -0.0125, -0.0373,  0.0772, -0.0257, -0.0459, -0.0874, -0.0175, -0.0578,\n",
       "                      -0.0077, -0.0548, -0.0325, -0.0155, -0.0102, -0.0336,  0.0186, -0.0556,\n",
       "                      -0.0684, -0.0603, -0.0080,  0.0994, -0.0419, -0.0191, -0.0427, -0.0148,\n",
       "                      -0.0193, -0.0551, -0.0591, -0.0287, -0.0735, -0.0095, -0.0028, -0.0234,\n",
       "                      -0.0645, -0.0254, -0.0222, -0.0118, -0.0088, -0.0055, -0.0233, -0.0264,\n",
       "                      -0.0127, -0.0277, -0.0533,  0.0404, -0.0574, -0.0112, -0.0809, -0.0104,\n",
       "                       0.0348, -0.0594,  0.0860, -0.0237, -0.0406,  0.0622, -0.0233, -0.0358,\n",
       "                      -0.0699,  0.1123, -0.0845, -0.0712,  0.0844, -0.0329, -0.0308, -0.0195,\n",
       "                      -0.0428, -0.0421, -0.0316, -0.0705, -0.0100, -0.0738, -0.0377, -0.0770,\n",
       "                      -0.0810, -0.0543, -0.0423, -0.0186,  0.0958, -0.0582, -0.0331, -0.0211,\n",
       "                      -0.0679, -0.0491, -0.0451,  0.0416, -0.0368, -0.0301, -0.0533, -0.0357,\n",
       "                      -0.0148, -0.0176, -0.0132, -0.0431, -0.0616, -0.0591, -0.0071, -0.0113,\n",
       "                      -0.0445, -0.0528, -0.0387, -0.0496,  0.0901, -0.0188, -0.0361, -0.0603,\n",
       "                      -0.0092, -0.0270, -0.0324, -0.0651, -0.0203,  0.1066, -0.0568, -0.0626,\n",
       "                      -0.0619, -0.0119,  0.1185, -0.0319, -0.0259, -0.0163, -0.0540, -0.0099,\n",
       "                      -0.0619, -0.0109, -0.0045, -0.0401, -0.0643, -0.0626, -0.0405, -0.0655,\n",
       "                      -0.0415, -0.0385, -0.0290,  0.0062, -0.0225, -0.0109,  0.1150, -0.0332,\n",
       "                      -0.0471, -0.0713, -0.0098, -0.0676, -0.0194, -0.0271, -0.0225, -0.0443,\n",
       "                       0.0657, -0.0381, -0.0189, -0.0397, -0.0223, -0.0427, -0.0480, -0.0322,\n",
       "                      -0.0119,  0.0830, -0.0106, -0.0345, -0.0641, -0.0685, -0.0224, -0.0188,\n",
       "                      -0.0441, -0.0099, -0.0671,  0.0544, -0.0430, -0.0077,  0.0346,  0.0827,\n",
       "                      -0.0098, -0.0327, -0.0159, -0.0314, -0.0299, -0.0439, -0.0381, -0.0524,\n",
       "                      -0.0571,  0.0977,  0.0824, -0.0181, -0.0080, -0.0018,  0.0918, -0.0298,\n",
       "                      -0.0398, -0.0282, -0.0255, -0.0102, -0.0475, -0.0177, -0.0114, -0.0623,\n",
       "                      -0.0627, -0.0703, -0.0368, -0.0135, -0.0484, -0.0527, -0.0240, -0.0143,\n",
       "                      -0.0141, -0.0410, -0.0556, -0.0158, -0.0073, -0.0341, -0.0299, -0.0294,\n",
       "                      -0.0304, -0.0226, -0.0583, -0.0280, -0.0219, -0.0044, -0.0258, -0.0687,\n",
       "                      -0.0872, -0.0410, -0.0252, -0.0104, -0.0468, -0.0395,  0.0018, -0.0752],\n",
       "                     device='cuda:0')),\n",
       "             ('book_norm.weight',\n",
       "              tensor([0.9580, 1.0217, 0.9984, 1.0080, 0.9294, 1.0089, 0.9993, 0.9191, 0.9671,\n",
       "                      1.0061, 1.0086, 1.0025, 1.0010, 0.9174, 0.9663, 0.9998, 1.0195, 0.9686,\n",
       "                      0.9772, 1.0123, 1.0063, 0.9960, 0.9967, 1.0196, 0.9434, 0.9938, 0.9212,\n",
       "                      0.9429, 1.0102, 0.9682, 1.0099, 0.9992, 0.9339, 0.9623, 1.0121, 0.8756,\n",
       "                      1.0191, 0.9816, 1.0196, 0.9004, 1.0089, 0.9816, 1.0228, 0.9777, 1.0150,\n",
       "                      1.0318, 0.9198, 0.9709, 0.9519, 0.9772, 1.0078, 1.0021, 0.9273, 0.9984,\n",
       "                      1.0251, 1.0017, 1.0060, 0.9968, 0.9677, 1.0162, 1.0326, 1.0196, 1.0160,\n",
       "                      1.0315, 0.9981, 1.0057, 0.9744, 1.0183, 0.9996, 1.0075, 1.0143, 0.9334,\n",
       "                      0.9654, 1.0028, 1.0230, 0.9135, 1.0090, 1.0051, 1.0001, 0.9467, 0.9971,\n",
       "                      1.0199, 1.0202, 0.9655, 1.0247, 0.9166, 1.0174, 1.0233, 1.0562, 0.9272,\n",
       "                      1.0186, 0.9891, 0.9614, 1.0091, 1.0288, 0.9659, 0.9136, 1.0026, 1.0031,\n",
       "                      1.0220, 1.0182, 1.0026, 1.0244, 1.0053, 0.9515, 1.0413, 0.9786, 0.9738,\n",
       "                      0.9504, 1.0344, 0.9979, 0.9534, 1.0127, 0.9999, 0.9938, 0.9684, 1.0382,\n",
       "                      0.9562, 1.0110, 1.0173, 1.0040, 0.9749, 0.9464, 0.9054, 0.9245, 1.0349,\n",
       "                      1.0010, 0.9683, 0.9712, 1.0186, 1.0103, 0.9730, 0.9669, 1.0639, 0.9287,\n",
       "                      1.0402, 0.9955, 0.9766, 1.0031, 0.9678, 1.0008, 0.9188, 1.0122, 0.9979,\n",
       "                      0.9785, 1.0254, 1.0046, 0.9802, 1.0030, 0.9572, 1.0184, 1.0011, 0.9974,\n",
       "                      1.0103, 1.0163, 0.9702, 0.9752, 1.0126, 0.9704, 1.0068, 1.0378, 1.0114,\n",
       "                      0.9992, 0.9974, 1.0075, 1.0042, 0.9551, 1.0155, 0.9968, 0.9642, 0.9604,\n",
       "                      1.0151, 1.0014, 1.0007, 0.9978, 0.9982, 0.9629, 1.0313, 0.9428, 1.0182,\n",
       "                      1.0273, 1.0270, 0.9304, 1.0103, 1.0064, 1.0208, 1.0085, 1.0359, 0.9493,\n",
       "                      1.0037, 0.9943, 1.0168, 1.0113, 1.0293, 1.0001, 1.0187, 1.0240, 1.0181,\n",
       "                      1.0473, 1.0161, 0.9559, 1.0045, 1.0107, 1.0452, 0.9598, 0.9755, 1.0089,\n",
       "                      0.8926, 1.0165, 0.9050, 1.0104, 1.0108, 1.0025, 1.0269, 1.0051, 0.9973,\n",
       "                      1.0065, 0.9946, 1.0039, 1.0251, 1.0185, 0.9800, 0.9523, 1.0053, 0.9778,\n",
       "                      0.9738, 0.9974, 1.0038, 0.9548, 0.9582, 0.9399, 1.0331, 1.0247, 0.9678,\n",
       "                      1.0129, 1.0136, 1.0159, 1.0019, 1.0025, 1.0230, 1.0197, 1.0098, 0.9970,\n",
       "                      1.0000, 0.9978, 1.0295, 0.9393, 1.0314, 1.0556, 0.9960, 0.9764, 0.9208,\n",
       "                      1.0177, 0.9550, 1.0047, 1.0459, 0.9668, 1.0080, 0.9971, 1.0105, 0.9750,\n",
       "                      1.0300, 1.0000, 0.9998, 1.0135, 0.9542, 1.0451, 1.0295, 0.9964, 0.9681,\n",
       "                      0.9753, 1.0201, 0.9488, 0.9722, 0.9752, 0.9075, 0.9812, 1.0101, 1.0071,\n",
       "                      1.0098, 1.0039, 1.0093, 0.9978, 1.0211, 1.0095, 1.0412, 0.9550, 1.0031,\n",
       "                      0.9990, 0.9725, 0.9195, 0.9696, 0.9990, 1.0288, 0.9599, 1.0112, 0.9934,\n",
       "                      1.0447, 0.9245, 0.9903, 1.0020, 1.0284, 0.9812, 1.0228, 1.0598, 1.0059,\n",
       "                      1.0009, 0.9250, 1.0140, 1.0011, 1.0099, 0.9955, 0.9734, 1.0150, 1.0154,\n",
       "                      1.0247, 1.0218, 1.0051, 0.9769, 0.9206, 1.0240, 1.0044, 1.0052, 0.9953,\n",
       "                      1.0042, 1.0065, 1.0062, 1.0055, 0.9795, 0.9332, 1.0310, 0.9551, 1.0099,\n",
       "                      0.9844, 1.0453, 1.0127, 0.9671, 1.0200, 0.9109, 0.9755, 1.0381, 0.9464,\n",
       "                      1.0204, 1.0212, 0.9099, 0.9469, 1.0306, 1.0386, 0.9332, 1.0013, 1.0015,\n",
       "                      0.9622, 1.0047, 1.0661, 0.9633, 0.9920, 0.9943, 1.0262, 0.9675, 1.0179,\n",
       "                      1.0358, 1.0220, 0.9748, 0.9966, 0.9368, 1.0281, 1.0201, 0.8988, 1.0168,\n",
       "                      1.0151, 1.0207, 0.9481, 1.0131, 1.0156, 1.0551, 1.0004, 0.9989, 1.0078,\n",
       "                      0.9966, 0.9611, 1.0145, 1.0063, 0.9930, 1.0105, 1.0142, 1.0163, 1.0326,\n",
       "                      1.0203, 0.9373, 1.0063, 0.9641, 1.0133, 1.0053, 1.0172, 0.9872, 1.0269,\n",
       "                      1.0001, 0.9437, 1.0250, 1.0092, 1.0256, 0.9944, 0.9745, 0.9742, 1.0140,\n",
       "                      1.0009, 1.0252, 1.0051, 1.0086, 0.9672, 1.0054, 0.8917, 1.0395, 1.0269,\n",
       "                      0.9687, 1.0077, 1.0044, 0.9735, 1.0105, 0.9450, 0.9700, 0.9860, 0.9618,\n",
       "                      1.0236, 1.0086, 1.0009, 0.9953, 1.0377, 1.0158, 0.9609, 0.9982, 0.9588,\n",
       "                      0.9132, 1.0076, 0.9710, 0.9950, 0.9964, 1.0178, 1.0199, 0.9599, 0.9949,\n",
       "                      0.9470, 0.9980, 1.0130, 1.0135, 1.0275, 0.9627, 0.9642, 1.0299, 1.0006,\n",
       "                      1.0257, 0.9751, 0.9724, 1.0122, 0.9544, 0.9407, 0.9990, 0.9611, 0.9949,\n",
       "                      1.0052, 1.0193, 0.9217, 1.0051, 1.0126, 0.9802, 0.9222, 0.9446, 0.9734,\n",
       "                      0.9992, 0.9947, 0.9390, 1.0089, 1.0160, 1.0074, 0.9644, 0.9969, 0.9525,\n",
       "                      1.0068, 0.9936, 1.0454, 1.0109, 1.0236, 0.9495, 1.0025, 1.0147, 0.9760,\n",
       "                      0.9964, 0.9970, 1.0063, 1.0129, 1.0008, 0.9981, 0.9824, 0.9575, 1.0233,\n",
       "                      1.0196, 0.9210, 0.9721, 1.0406, 0.9860, 0.9477, 0.9989, 0.9703, 1.0145,\n",
       "                      1.0333, 1.0082, 1.0018, 1.0160, 1.0543, 1.0313, 0.9546, 1.0129],\n",
       "                     device='cuda:0')),\n",
       "             ('book_norm.bias',\n",
       "              tensor([-0.0248, -0.0447, -0.0147, -0.0311, -0.0342, -0.0797, -0.0193, -0.0253,\n",
       "                      -0.0230, -0.0708, -0.0192, -0.0464, -0.0114,  0.1049, -0.0220, -0.0250,\n",
       "                      -0.0516, -0.0498, -0.0306, -0.0295, -0.0198, -0.0358, -0.0023, -0.0422,\n",
       "                      -0.0376, -0.0128,  0.1081,  0.0672, -0.0403, -0.0150, -0.0376, -0.0105,\n",
       "                      -0.0261, -0.0196, -0.0268,  0.0829, -0.0798, -0.0222, -0.0254,  0.0599,\n",
       "                      -0.0225,  0.0204, -0.0303, -0.0059, -0.0024, -0.0344, -0.0324, -0.0224,\n",
       "                       0.0612, -0.0023, -0.0293, -0.0043,  0.1019, -0.0261, -0.0461, -0.0079,\n",
       "                      -0.0246, -0.0138, -0.0118, -0.0191, -0.0289, -0.0428, -0.0189, -0.0778,\n",
       "                      -0.0126, -0.0211, -0.0314, -0.0243, -0.0598, -0.0424, -0.0408,  0.1103,\n",
       "                       0.0772, -0.0312, -0.0214,  0.0734, -0.0438, -0.0198, -0.0102, -0.0343,\n",
       "                       0.0017, -0.0294, -0.0473, -0.0032, -0.0129,  0.0754, -0.0079, -0.0516,\n",
       "                      -0.0714, -0.0198, -0.0549, -0.0198,  0.0730, -0.1054, -0.0442,  0.0106,\n",
       "                       0.0985, -0.0144, -0.0215, -0.0754, -0.0255, -0.0539, -0.0875, -0.0169,\n",
       "                      -0.0316, -0.0991, -0.0233, -0.0299, -0.0273, -0.0702, -0.0235, -0.0296,\n",
       "                      -0.0178, -0.0210,  0.0009, -0.0154, -0.0524, -0.0341, -0.0279, -0.0426,\n",
       "                      -0.0298, -0.0219,  0.0323,  0.0922,  0.1023, -0.0375, -0.0172, -0.0195,\n",
       "                      -0.0177, -0.0268, -0.0156, -0.0306,  0.0101, -0.0754, -0.0449, -0.0618,\n",
       "                       0.0010, -0.0100, -0.0065, -0.0054, -0.0079,  0.1064, -0.0427, -0.0269,\n",
       "                      -0.0217, -0.0557, -0.0530, -0.0408, -0.0301, -0.0349, -0.0519, -0.0278,\n",
       "                      -0.0059, -0.0188, -0.0363, -0.0209, -0.0268, -0.1030, -0.0301, -0.0202,\n",
       "                      -0.0699, -0.0305, -0.0206, -0.0044, -0.0128, -0.0145,  0.0147, -0.0182,\n",
       "                      -0.0161, -0.0288, -0.0239, -0.0191, -0.0053, -0.0231, -0.0284, -0.0006,\n",
       "                      -0.0288, -0.0612,  0.0456, -0.0457, -0.0437, -0.0335,  0.0634, -0.0276,\n",
       "                      -0.0390, -0.0390, -0.0234, -0.0474, -0.0432, -0.0190, -0.0141, -0.0208,\n",
       "                      -0.0351, -0.0490, -0.0206, -0.0813, -0.0486, -0.0226, -0.0955, -0.0260,\n",
       "                       0.0632, -0.0349, -0.0149, -0.0579,  0.0479,  0.0310, -0.0599,  0.1167,\n",
       "                      -0.0207,  0.1053, -0.0419, -0.0187, -0.0129, -0.0582, -0.0594, -0.0258,\n",
       "                      -0.0270, -0.0161, -0.0076, -0.0719, -0.0312,  0.0093,  0.0066, -0.0273,\n",
       "                      -0.0106, -0.0077, -0.0245, -0.0148, -0.0260, -0.0317, -0.0072, -0.0749,\n",
       "                      -0.0898,  0.0231, -0.0191, -0.0339, -0.0308, -0.0189, -0.0219, -0.0615,\n",
       "                      -0.0790, -0.0296, -0.0149, -0.0096, -0.0064, -0.0728, -0.0395, -0.0631,\n",
       "                      -0.0268, -0.0242, -0.0143,  0.0678, -0.0185, -0.0309, -0.0254, -0.0796,\n",
       "                      -0.0123, -0.0639, -0.0068, -0.0309, -0.0170, -0.0824, -0.0067, -0.0203,\n",
       "                      -0.0964,  0.0313, -0.0814, -0.0920, -0.0203, -0.0072, -0.0371, -0.0439,\n",
       "                      -0.0169, -0.0202, -0.0013, -0.0258, -0.0106, -0.0471, -0.0157, -0.0289,\n",
       "                      -0.0163, -0.0180, -0.0234, -0.0697, -0.0260, -0.0473, -0.0390, -0.0710,\n",
       "                      -0.0170, -0.0216, -0.0028, -0.0024, -0.0166, -0.0266,  0.0116, -0.0115,\n",
       "                      -0.0201, -0.0561,  0.1166, -0.0037, -0.0257, -0.0512, -0.0240, -0.0406,\n",
       "                      -0.1031, -0.0165, -0.0233, -0.0404, -0.0423, -0.0155, -0.0241, -0.0011,\n",
       "                      -0.0161, -0.0554, -0.0303, -0.0389, -0.0213, -0.0271, -0.0158,  0.1029,\n",
       "                      -0.0587, -0.0169, -0.0246, -0.0354, -0.0505, -0.0360, -0.0181, -0.0283,\n",
       "                      -0.0362,  0.1017, -0.0895, -0.0349, -0.0103,  0.0087, -0.0649, -0.0682,\n",
       "                      -0.0287, -0.0221, -0.0258, -0.0180, -0.0689, -0.0203, -0.0780, -0.0443,\n",
       "                       0.1015, -0.0296, -0.0296, -0.0563, -0.0284, -0.0414, -0.0154, -0.0175,\n",
       "                      -0.0132, -0.0717,  0.0321, -0.0138, -0.0120, -0.0297,  0.0030, -0.0156,\n",
       "                      -0.0193, -0.0285,  0.0048, -0.0164, -0.0312, -0.0460, -0.0133,  0.0899,\n",
       "                      -0.0267, -0.0293, -0.0340, -0.0471, -0.0149, -0.0191, -0.0913, -0.0109,\n",
       "                      -0.0479, -0.0675, -0.0388,  0.0074, -0.0265, -0.0681, -0.0130, -0.0662,\n",
       "                      -0.0517, -0.0524, -0.0557, -0.0229, -0.0247, -0.0290,  0.0115, -0.0297,\n",
       "                      -0.0324, -0.0282, -0.0378, -0.0871, -0.0228, -0.0385, -0.0372, -0.0280,\n",
       "                      -0.0286, -0.0232, -0.0241, -0.0146, -0.0301, -0.0217, -0.0553, -0.0285,\n",
       "                      -0.0063, -0.0269, -0.0474,  0.0874, -0.0604, -0.0473, -0.0054, -0.0196,\n",
       "                      -0.0190, -0.0085, -0.0197, -0.0273, -0.0265, -0.0307, -0.0254, -0.0500,\n",
       "                      -0.0504, -0.0093, -0.0018, -0.0560, -0.0359, -0.0223, -0.0296,  0.0251,\n",
       "                      -0.0366, -0.0188, -0.0326, -0.0137, -0.0231, -0.0370, -0.0341, -0.0008,\n",
       "                      -0.0143, -0.0225, -0.0071, -0.0831, -0.0283, -0.0399, -0.0042,  0.0202,\n",
       "                      -0.0491, -0.0249, -0.0410, -0.0203, -0.0045, -0.0426, -0.0410, -0.0356,\n",
       "                      -0.0606, -0.0143,  0.0007, -0.0349, -0.0421,  0.1112, -0.0262, -0.0247,\n",
       "                      -0.0195, -0.0315, -0.0218, -0.0109, -0.0195, -0.0098, -0.0335, -0.0182,\n",
       "                      -0.0270, -0.0331, -0.0277, -0.0261,  0.0288, -0.0452, -0.0196, -0.0546,\n",
       "                      -0.0294, -0.0190,  0.0500, -0.0401, -0.0338, -0.0094, -0.0211, -0.0026,\n",
       "                      -0.0188, -0.0593, -0.0240, -0.0131, -0.0072,  0.0426, -0.0499, -0.0237,\n",
       "                       0.1072, -0.0158, -0.0479, -0.0065,  0.0864, -0.0672, -0.0165, -0.0314,\n",
       "                      -0.0458, -0.0276, -0.0220, -0.0737, -0.0801, -0.0859, -0.0245, -0.0223],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
